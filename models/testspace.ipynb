{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce05621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import List\n",
    "def ConvBlock(out_channels:int,\n",
    "             kernel_size:int=3,\n",
    "             stride:tuple=(1,1),\n",
    "             padding:str=\"same\",\n",
    "             activation:str=None,\n",
    "             initializer:str=\"he_normal\",\n",
    "             bn:bool=False,\n",
    "             dropout_rate:float=0,\n",
    "             pooling=None,\n",
    "            x:\"Input\"=None): # ConvBlock for backbone feature extraction.\n",
    "    assert x is not None, \"Did not provide input to the layer. Won't be able to build computational graph.\"\n",
    "    x = Conv2D(out_channels,\n",
    "                    kernel_size,\n",
    "                    activation=activation,\n",
    "                    padding=padding,\n",
    "                    kernel_initializer=initializer,\n",
    "                    use_bias=not bn,\n",
    "                    )(x)\n",
    "    if bn:\n",
    "        x = BatchNormalization()(x)\n",
    "    if dropout_rate>0:\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "    if pooling:\n",
    "        assert pooling in POOLS.keys(), \"Not valid pooling method.\"\n",
    "        x = POOLS[pooling](pool_size=(2, 2))(x)\n",
    "    return x\n",
    "    \n",
    "def OutputBlock(x,\n",
    "                n_classes:int,\n",
    "                hidden_nodes:List[int]=None,\n",
    "                hidden_activation:str=\"relu\"):\n",
    "    x = Flatten()(x)\n",
    "    if hidden_nodes:\n",
    "        for i in range(len(hidden_nodes)):\n",
    "            x = Dense(hidden_nodes[i],activation=hidden_activation)(x)\n",
    "    y = Dense(n_classes,activation=\"softmax\")(x)\n",
    "    return y\n",
    "    \n",
    "def ResBlock(out_channels:int,\n",
    "             kernel_size:int=3,\n",
    "             stride:tuple=(1,1),\n",
    "             dropout_rate:float=0, # Dropout between main line segments.\n",
    "             depth = 2, # Depth of main line.\n",
    "            x:\"Input\"=None):\n",
    "    act = Activation(\"relu\")\n",
    "    skip = Conv2D(out_channels,\n",
    "                    1,\n",
    "                    activation=None,\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    use_bias=False,\n",
    "                    )(x)\n",
    "    for i in range(depth): \n",
    "        x = Conv2D(out_channels,\n",
    "                    kernel_size,\n",
    "                    activation=None,\n",
    "                    padding=\"same\",\n",
    "                    kernel_initializer=\"he_normal\",\n",
    "                    use_bias=False,\n",
    "                    )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = act(x)\n",
    "    y = act(skip+x)\n",
    "    return y\n",
    "def build_resnet(height, width, channels):\n",
    "    inp = Input(shape=(height, width, channels), name='input_1')\n",
    "    act = Activation(\"relu\")\n",
    "    drop = 0.8\n",
    "    initial_filters = 16\n",
    "    x = Conv2D(filters=initial_filters,kernel_size=7,strides=(2,2),padding=\"same\",use_bias=False)(inp)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    # Layer 1.\n",
    "    x = ResBlock(initial_filters*2,x=x,depth=1)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    # Layer 2\n",
    "    x = ResBlock(initial_filters*4,x=x,depth=1)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    # Layer 3\n",
    "    x = ResBlock(initial_filters*8,x=x,depth=1)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    # Layer 4\n",
    "    x = ResBlock(initial_filters*8,x=x,depth=1)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    # Layer 5\n",
    "    x = ResBlock(initial_filters*16,x=x,depth=1)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    # Layer 6\n",
    "    x = ResBlock(initial_filters*16,x=x,depth=1)\n",
    "    x = MaxPooling2D(pool_size=(2,2))(x)\n",
    "    # FC layer\n",
    "    flat = Flatten()(x)\n",
    "    flat = Dense(128, activation='relu')(flat)\n",
    "    flat = Dense(32, activation='relu')(flat)\n",
    "    y = Dense(4, activation='softmax')(flat)\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[y])\n",
    "\n",
    "def confusion(model,gen_data, break_point:int=None):\n",
    "    # Comparing Confusion matrix from Scikit with \n",
    "    preds = []\n",
    "    ls = []\n",
    "    labels = np.concatenate((t1_label,t1ce_label,t2_label, flair_label), axis=0)\n",
    "    # Test Validation\n",
    "    for idx, (t1, t1ce,t2,flair) in enumerate(gen_data):\n",
    "        images = np.concatenate((t1, t1ce, t2, flair), axis=0)\n",
    "        ls.append(labels.argmax(1))\n",
    "        pred = model.predict_on_batch(images)\n",
    "        preds.append(pred.argmax(1))\n",
    "        if break_point and idx>=break_point-1:\n",
    "            break\n",
    "    result = confusion_matrix(np.array(ls).flatten(), np.array(preds).flatten(), normalize='pred')\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = result, display_labels = array_labels)\n",
    "    return np.array(preds),np.array(ls),result,cm_display\n",
    "def test_model(model):\n",
    "    train_preds,train_labels,cm_train,cm_disp_train = confusion(model,gen_train,len(gen_val))\n",
    "    print(f\"Training set - Accuracy: {mean_average_accuracy(cm_train)}\")\n",
    "    cm_disp_train.plot()\n",
    "    plt.plot()\n",
    "    val_preds,val_labels,cm_val,cm_disp_val = confusion(model,gen_val)\n",
    "    print(f\"Validation set - Accuracy: {mean_average_accuracy(cm_val)}\")\n",
    "    cm_disp_val.plot()\n",
    "    plt.plot()\n",
    "    test_preds,test_labels,cm_test,cm_disp_test = confusion(model,gen_test)\n",
    "    print(f\"Test set - Accuracy: {mean_average_accuracy(cm_test)}\")\n",
    "    cm_disp_test.plot()\n",
    "    plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
