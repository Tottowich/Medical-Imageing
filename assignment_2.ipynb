{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1aa4eab",
   "metadata": {},
   "source": [
    "# Assingment 2 - Contrast transfer\n",
    "### Course: Convolutional Neural Networks with Applications in Medical Image Analysis\n",
    "\n",
    "For the second assignment we will use the same dataset as before! Previously you have classified the available contrasts of the same anatomy, and for this assignment you will train an image to image model to generate one contrast from another. The task is to take T1-weighted images as inputs, and generate the corresponding T2-weighted images.\n",
    "\n",
    "Your tasks, to include in the Jupyter notebook you hand in, are:\n",
    "- Reach a validation MSE below 0.015 on the validation set, and describe what parameter combinations you have gone through to reach those results.\n",
    "- Describe the effect of each hyper-parameter you have changed, and the way you have experimented with them. What problems did you face? What happened when the training failed? Try describing everything that you have learnt.\n",
    "- Answer the questions set in notes\n",
    "\n",
    "Upload the updated notebook to canvas, that also contains your answers to the questions above. The deadline for the assignment is March $30^{th}$, 15:00.\n",
    "\n",
    "Good luck and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6cc435e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 00:08:03.503583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-27 00:08:04.026795: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theodor/anaconda3/envs/tf/lib/\n",
      "2023-03-27 00:08:04.026848: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/theodor/anaconda3/envs/tf/lib/\n",
      "2023-03-27 00:08:04.026999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (4.65.0)\n",
      "Requirement already satisfied: keras-tuner in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: requests in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner) (2.28.2)\n",
      "Requirement already satisfied: ipython in /home/theodor/.local/lib/python3.9/site-packages (from keras-tuner) (8.4.0)\n",
      "Requirement already satisfied: packaging in /home/theodor/.local/lib/python3.9/site-packages (from keras-tuner) (21.3)\n",
      "Requirement already satisfied: tensorflow>=2.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner) (2.11.0)\n",
      "Requirement already satisfied: kt-legacy in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from keras-tuner) (1.0.4)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (1.16.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (1.24.2)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (3.8.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (1.51.3)\n",
      "Requirement already satisfied: setuptools in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (65.6.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (0.31.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorflow>=2.0->keras-tuner) (23.3.3)\n",
      "Requirement already satisfied: stack-data in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (0.3.0)\n",
      "Requirement already satisfied: backcall in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython->keras-tuner) (5.7.1)\n",
      "Requirement already satisfied: decorator in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (5.1.1)\n",
      "Requirement already satisfied: matplotlib-inline in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from ipython->keras-tuner) (3.0.36)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (2.12.0)\n",
      "Requirement already satisfied: pickleshare in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/theodor/.local/lib/python3.9/site-packages (from ipython->keras-tuner) (4.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/theodor/.local/lib/python3.9/site-packages (from packaging->keras-tuner) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/theodor/.local/lib/python3.9/site-packages (from jedi>=0.16->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/theodor/.local/lib/python3.9/site-packages (from pexpect>4.3->ipython->keras-tuner) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/theodor/.local/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->keras-tuner) (0.2.5)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
      "Requirement already satisfied: pure-eval in /home/theodor/.local/lib/python3.9/site-packages (from stack-data->ipython->keras-tuner) (0.2.2)\n",
      "Requirement already satisfied: asttokens in /home/theodor/.local/lib/python3.9/site-packages (from stack-data->ipython->keras-tuner) (2.0.5)\n",
      "Requirement already satisfied: executing in /home/theodor/.local/lib/python3.9/site-packages (from stack-data->ipython->keras-tuner) (0.8.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/theodor/anaconda3/envs/tf/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(2023)  # Set seed for reproducibility\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.random.set_seed(2026) # Note: Different to test different initializations.\n",
    "!pip install tqdm # Adding tqdm to use progress bars. Unbarable waiting for each epoch to finish without feedback.\n",
    "from tqdm import tqdm\n",
    "!pip install keras-tuner # NOTE: Adding keras tuner to use hyperparameter tuning.\n",
    "import keras_tuner as kt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1b52933",
   "metadata": {},
   "source": [
    "## Visualization / Typing imports\n",
    "I've imported some more visualization and typing libraries for ease of use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e2b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ImageGrid to plot the encodings.\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb49a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU(s) available (using '/physical_device:GPU:0'). Training will be lightning fast!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 00:08:07.415808: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-27 00:08:07.419632: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-27 00:08:07.419884: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(f\"GPU(s) available (using '{gpus[0].name}'). Training will be lightning fast!\")\n",
    "else:\n",
    "    print(\"No GPU(s) available. Training will be suuuuper slow!\")\n",
    "\n",
    "# NOTE: These are the packages you will need for the assignment.\n",
    "# NOTE: You are encouraged to use the course virtual environment, which already has GPU support."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da9b061e",
   "metadata": {},
   "source": [
    "## DataGenerator and Generator setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c238ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 arrays,\n",
    "                 batch_size=32,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.arrays = arrays\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        self.file_idx = 0\n",
    "        self.file_list = [self.data_path + '/' + s for s in\n",
    "                          os.listdir(self.data_path)]\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        with np.load(self.file_list[0]) as npzfile:\n",
    "            self.in_dims = []\n",
    "            self.n_channels = 1\n",
    "            for i in range(len(self.arrays)):\n",
    "                im = npzfile[self.arrays[i]]\n",
    "                self.in_dims.append((self.batch_size,\n",
    "                                    *np.shape(im),\n",
    "                                    self.n_channels))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.floor((len(self.file_list)) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                               self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.file_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        a = self.__data_generation(list_IDs_temp)\n",
    "        return a\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indexes after each epoch.\"\"\"\n",
    "        self.indexes = np.arange(len(self.file_list))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    #@threadsafe_generator\n",
    "    def __data_generation(self, temp_list):\n",
    "        \"\"\"Generate data containing batch_size samples.\"\"\"\n",
    "        # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        arrays = []\n",
    "\n",
    "        for i in range(len(self.arrays)):\n",
    "            arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n",
    "\n",
    "        for i, ID in enumerate(temp_list):\n",
    "            with np.load(ID) as npzfile:\n",
    "                for idx in range(len(self.arrays)):\n",
    "                    x = npzfile[self.arrays[idx]] \\\n",
    "                        .astype(np.single)\n",
    "                    x = np.expand_dims(x, axis=2)\n",
    "                    x_max = np.max(x)\n",
    "                    if x_max > 0:\n",
    "                        x /= x_max\n",
    "                    arrays[idx][i, ] = x\n",
    "        return arrays\n",
    "\n",
    "# NOTE: Don't change the data generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d606d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dir = './data/' # Change if you have copied the data locally on your machine \n",
    "array_labels = ['t1', 't2']  # Available arrays are: 't1', 't1ce', 't2', 'flair', 'mask'.\n",
    "batch_size = 32\n",
    "\n",
    "gen_train = DataGenerator(data_path=gen_dir + 'training',\n",
    "                          arrays=array_labels,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "gen_val = DataGenerator(data_path=gen_dir + 'validating',\n",
    "                        arrays=array_labels,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "gen_test = DataGenerator(data_path=gen_dir + 'testing',\n",
    "                         arrays=array_labels,\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "# NOTE: What arrays are you using? You can use multiple contrasts as inputs, if you'd like.\n",
    "# NOTE: What batch size are you using? Should you use more? Or less?\n",
    "# NOTE: Are you using the correct generators for the correct task? Training for training and validating for validating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00e81cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imgs = gen_train[0]\n",
    "# for inp in range(np.shape(imgs)[0]):\n",
    "#     plt.figure(figsize=(12,5))\n",
    "#     for i in range(4):\n",
    "#         plt.subplot(1, 4, i + 1)\n",
    "#         plt.imshow(imgs[inp][i, :, :, 0], cmap='gray')\n",
    "#         plt.colorbar()\n",
    "#         plt.title('Image size: ' + str(np.shape(imgs[inp][i, :, :, 0])))\n",
    "#         plt.tight_layout()\n",
    "#     plt.suptitle('Array: ' + gen_train.arrays[inp])\n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9202fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(x:np.ndarray,y:np.ndarray,n:int=3,title:str='Sample of inputs and labels'):\n",
    "    \"\"\"Plot a sample of the images and masks.\"\"\"\n",
    "    fig, ax = plt.subplots(2, n, figsize=(12, 5))\n",
    "    for i in range(n):\n",
    "        ax[0, i].imshow(x[i, :, :, 0], cmap='gray')\n",
    "        ax[0, i].set_title('T1')\n",
    "        ax[1, i].imshow(y[i, :, :, 0], cmap='gray')\n",
    "        ax[1, i].set_title('T2')\n",
    "        # Colorbar\n",
    "        fig.colorbar(ax[0, i].imshow(x[i, :, :, 0], cmap='gray'), ax=ax[0, i])\n",
    "        fig.colorbar(ax[1, i].imshow(y[i, :, :, 0], cmap='gray'), ax=ax[1, i])\n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Add label to the left of the figure\n",
    "# %matplotlib inline\n",
    "# x,y = gen_train[0]\n",
    "# plot_sample(x,y,4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6575d103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images : 8000\n",
      "Training batch size       : [(32, 256, 256, 1), (32, 256, 256, 1)]\n"
     ]
    }
   ],
   "source": [
    "# A quick summary of the data:\n",
    "print(f\"Number of training images : {len(gen_train.file_list)}\")\n",
    "print(f\"Training batch size       : {gen_train.in_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79ebe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages important for building and training your model.\n",
    "# import keras\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Flatten, Input\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, Nadam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "921a3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import Tensor\n",
    "from keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "                        Add, AveragePooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model():\n",
    "    filt_size = 2\n",
    "    input1 = Input(shape=(256, 256, 1))\n",
    "\n",
    "    conv1 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(input1)\n",
    "    conv1 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filt_size * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(filt_size * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(filt_size * 8, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(filt_size * 4, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(filt_size * 2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(filt_size, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation=\"exponential\")(conv9)\n",
    "\n",
    "    return Model(inputs=input1, outputs=conv10)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "097c9323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = build_model()\n",
    "# m.summary()\n",
    "# m.compile(optimizer=Adam(lr=1e-4), loss='mse')\n",
    "# m.fit(gen_train, epochs=10, validation_data=gen_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b08677d",
   "metadata": {},
   "source": [
    "## Training Setup - Hyperparameters\n",
    "Setting up hyperparameters for training along with hyperparameter tuning module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "308bb577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "W,H,C = 256,256,1\n",
    "input_shape = (W,H,C)\n",
    "num_classes = C # Number of classes is equal to the number of channels in the output\n",
    "# Define the hyper parameters which will be tuned.\n",
    "# Model Parameters\n",
    "filters = [2**i for i in range(1,4)]\n",
    "activations = [\"relu\",\"selu\",\"gelu\",\"tanh\"]\n",
    "drop_rates = [0.0,0.01,0.05,0.1,0.2]\n",
    "output_activation = \"softmax\"\n",
    "batch_norm = [True,False]\n",
    "# Training Parameters\n",
    "learning_rates = [1e-2,5e-3,1e-3,5e-4]\n",
    "weight_decay = [1e-1,1e-2,1e-3,1e-4]\n",
    "clipnorm = [2.0,1.0,0.5,0.1]\n",
    "optimizers = [\"Adam\",\"RMSprop\",\"Nadam\"]\n",
    "str2optimizer = {\"Adam\":Adam,\"RMSprop\":RMSprop,\"Nadam\":Nadam}\n",
    "# Fixed Parameters\n",
    "max_epochs = 50\n",
    "output_activation = \"sigmoid\" # Our regression values are between 0 and 1, hence -> sigmoid.\n",
    "loss = \"mse\"\n",
    "early_stop = EarlyStopping(monitor=\"val_loss\",patience=6)\n",
    "# Project Parameters\n",
    "project_name = \"Unet\"\n",
    "project_dir = \"./theodorjonsson_tuner/\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6a8423d",
   "metadata": {},
   "source": [
    "## Model Build Function\n",
    "Function used to build and compiled the model used for hyperparameter tuning on the training set.\n",
    "This function uses the hyperparameters in the code section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d35a9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model_hp(hp:kt.HyperParameters):\n",
    "    input1 = Input(shape=input_shape)\n",
    "    # Training Parameters\n",
    "    hp_learning_rate = hp.Choice(\"learning_rate\",values=learning_rates)\n",
    "    hp_weight_decay = hp.Choice(\"weight_decay\",values=weight_decay)\n",
    "    hp_clipnorm = hp.Choice(\"clipnorm\",values=clipnorm)\n",
    "    hp_optimizer = str2optimizer[hp.Choice(\"optimizer\",values=optimizers)]\n",
    "    optimizer = hp_optimizer(learning_rate=hp_learning_rate,\n",
    "                             clipnorm=hp_clipnorm,\n",
    "                             decay=hp_weight_decay)\n",
    "    # Model Parameters\n",
    "    hp_filter = hp.Choice(\"filters\",values=filters)\n",
    "    hp_activation = hp.Choice(\"activation\",values=activations)\n",
    "    hp_drop_rate_encoder = hp.Choice(\"drop_rate_encoder\",values=drop_rates)\n",
    "    hp_drop_rate_decoder = hp.Choice(\"drop_rate_decoder\",values=drop_rates)\n",
    "    hp_batch_norm = hp.Choice(\"batch_norm\",values=batch_norm)\n",
    "    # Layer 1\n",
    "    conv1 = Conv2D(hp_filter, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(input1)\n",
    "    if hp_batch_norm:\n",
    "        conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(hp_filter, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    # Layer 2\n",
    "    conv2 = Conv2D(hp_filter * 2, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    if hp_batch_norm:\n",
    "        conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(hp_filter * 2, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    # Layer 3\n",
    "    conv3 = Conv2D(hp_filter * 4, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    if hp_batch_norm:\n",
    "        conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(hp_filter * 4, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    # Layer 4\n",
    "    conv4 = Conv2D(hp_filter * 8, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    if hp_batch_norm:\n",
    "        conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(hp_filter * 8, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(hp_drop_rate_encoder)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    # Layer 5 Bottle Neck\n",
    "    conv5 = Conv2D(hp_filter * 16, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    if hp_batch_norm:\n",
    "        conv5 = BatchNormalization()(conv5)\n",
    "    conv5 = Conv2D(hp_filter * 16, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(hp_drop_rate_encoder)(conv5)\n",
    "    # Layer 6 Decoder with skip connection\n",
    "    up6 = Conv2D(hp_filter * 8, 2, activation=hp_activation, padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(hp_filter * 8, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    if hp_batch_norm:\n",
    "        conv6 = BatchNormalization()(conv6)\n",
    "    conv6 = Dropout(hp_drop_rate_decoder)(conv6)\n",
    "    conv6 = Conv2D(hp_filter * 8, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv6)\n",
    "    # Layer 7\n",
    "    up7 = Conv2D(hp_filter * 4, 2, activation=hp_activation, padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(hp_filter * 4, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    if hp_batch_norm:\n",
    "        conv7 = BatchNormalization()(conv7)\n",
    "    conv7 = Dropout(hp_drop_rate_decoder)(conv7)\n",
    "    conv7 = Conv2D(hp_filter * 4, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv7)\n",
    "    # Layer 8\n",
    "    up8 = Conv2D(hp_filter * 2, 2, activation=hp_activation, padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(hp_filter * 2, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    if hp_batch_norm:\n",
    "        conv8 = BatchNormalization()(conv8)\n",
    "    conv8 = Conv2D(hp_filter * 2, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv8)\n",
    "    # Layer 9\n",
    "    up9 = Conv2D(hp_filter, 2, activation=hp_activation, padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(hp_filter, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    if hp_batch_norm:\n",
    "        conv9 = BatchNormalization()(conv9)\n",
    "    conv9 = Conv2D(hp_filter, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation=hp_activation, padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(C, 1, activation=output_activation)(conv9)\n",
    "\n",
    "    model = Model(inputs=input1, outputs=conv10)\n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f916f340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 14 Complete [00h 04m 35s]\n",
      "val_loss: 0.005692091304808855\n",
      "\n",
      "Best val_loss So Far: 0.0028183823451399803\n",
      "Total elapsed time: 00h 39m 36s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Create the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model_hp,\n",
    "    objective='val_loss',\n",
    "    max_epochs=max_epochs,\n",
    "    directory=project_dir,\n",
    "    project_name=project_name,\n",
    "    factor=6,\n",
    "    seed=0,\n",
    ")\n",
    "tuner.search(gen_train, validation_data=gen_val, epochs=max_epochs, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b44f3d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the best hyperparameters and initialize the model for training.\n",
    "hyps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model:Model = tuner.hypermodel.build(hyps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74b7cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best hyperparameters: {hyps.get_config()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a35fc342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-27 08:12:34.846313: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel_4/dropout_16/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/250 [..............................] - ETA: 16:56 - loss: 0.2026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29026/1025315803.py:62: RuntimeWarning: overflow encountered in cast\n",
      "  arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - ETA: 0s - loss: 0.0069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29026/1025315803.py:62: RuntimeWarning: invalid value encountered in cast\n",
      "  arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 41s 149ms/step - loss: 0.0069 - val_loss: 0.0141\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.0037 - val_loss: 0.0209\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.0031 - val_loss: 0.0044\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 6/50\n",
      "218/250 [=========================>....] - ETA: 4s - loss: 0.0022"
     ]
    }
   ],
   "source": [
    "# Use the same callbacks and data before.\n",
    "history = model.fit(gen_train, validation_data=gen_val, epochs=max_epochs, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc5e0c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'weight_decay': 0.01, 'clipnorm': 0.5, 'optimizer': 'Nadam', 'filters': 8, 'activation': 'relu', 'drop_rate_encoder': 0.2, 'drop_rate_decoder': 0.0, 'batch_norm': 1, 'tuner/epochs': 25, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "print(hyps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e24a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Are the input sizes correct?\n",
    "# NOTE: Do you have the correct number of input images?\n",
    "# NOTE: Are the output sizes correct?\n",
    "# NOTE: Do you have the correct number of output images?\n",
    "# NOTE: What's the range of the output? Can you use an activation as a regularizer?\n",
    "# NOTE: Try to imagine the model layer-by-layer and think it through. Is it doing something reasonable?\n",
    "# NOTE: Are your parameters split evenly inside the model? Try making \"too large\" layers smaller\n",
    "# NOTE: Will the model fit into memory? Is the model too small? Is the model too large?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4068ee43",
   "metadata": {},
   "source": [
    "## Augmentation Class\n",
    "I've implemented a set of classes used to augment the input training data. The implemented augmentations are: \n",
    "- **Flip**: Flips the image along the x or y axis\n",
    "- **Rotate**: Rotates the image by a random angle.\n",
    "- **Noise**: Adds random gaussian noise to the image.\n",
    "- **Mask**: Masks a random number of sections of random size with zeros.\n",
    "- **Translate**: Translates the image by a random number of pixels.\n",
    "- **Shear**: Shears the image by a random angle.\n",
    "\n",
    "Note: **Rotate**, **Shear** and **Translate** are implemented using the **Affine** transformation and are currently very slow. Therefore I have not used them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation class for used in the training pipeline.\n",
    "# float wrapper for probability\n",
    "def prob(p: float) -> bool:\n",
    "    return np.random.random() < p\n",
    "class Augmentation:\n",
    "    verbose: bool = False\n",
    "    # Parent class for all augmentations\n",
    "    def __init__(self, p: float):\n",
    "        self.p = p\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.__class__.__name__\n",
    "    def __call__(self, x: np.ndarray,y: np.ndarray) -> np.ndarray:\n",
    "        if prob(self.p):\n",
    "            if self.verbose:\n",
    "                print(f\"Augmenting: Applying {self.name}\")\n",
    "            return self.augment(x,y)\n",
    "        else:\n",
    "            return x,y\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "class Flip(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, axis: int = 0):\n",
    "        super().__init__(p)\n",
    "        self.axis = axis # 1 for horizontal, 0 for vertical\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        return np.flip(x, axis=self.axis),np.flip(y, axis=self.axis)\n",
    "\n",
    "class Rotate(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, angle: float = np.pi/4):\n",
    "        super().__init__(p)\n",
    "        self.angle = angle\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        # Rotate image and fill with zeros\n",
    "        # Random angle between -angle and angle\n",
    "        angle = np.random.uniform(-self.angle, self.angle)\n",
    "        # return rotate(x, angle, resize=False, mode=\"constant\", cval=0),rotate(y, angle, resize=False, mode=\"constant\", cval=0)\n",
    "        # Batched rotate\n",
    "        return np.array([rotate(img, angle, resize=False, mode=\"constant\", cval=0) for img in x]),np.array([rotate(img, angle, resize=False, mode=\"constant\", cval=0) for img in y])\n",
    "class Noise(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, mean: float = 0.0, std: float = 0.1):\n",
    "        super().__init__(p)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        noise = np.random.normal(self.mean, self.std, x.shape)\n",
    "        return (x + noise, y)\n",
    "\n",
    "class Mask(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, max_n_masks: int = 10, mask_size: float = 0.5):\n",
    "        super().__init__(p)\n",
    "        self.max_n_masks = max_n_masks\n",
    "        self.mask_size = mask_size\n",
    "    def augment(self, x: np.ndarray, y:np.ndarray) -> np.ndarray:\n",
    "        # Random number of masks\n",
    "        n_masks = np.random.randint(1, self.max_n_masks)\n",
    "        w = x.shape[-3]\n",
    "        h = x.shape[-2]\n",
    "        for _ in range(n_masks):\n",
    "            # Random mask size\n",
    "            mask_size = np.random.uniform(low=self.mask_size/2, high=self.mask_size)\n",
    "            # Random mask position\n",
    "            x1 = np.random.randint(0, w)\n",
    "            y1 = np.random.randint(0, h)\n",
    "            x2 = int(x1 + w * mask_size)\n",
    "            y2 = int(y1 + h * mask_size)\n",
    "            x[:, x1:x2, y1:y2,:] = 0\n",
    "        return (x, y)\n",
    "\n",
    "class Translate(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, factor: float = 0.5):\n",
    "        super().__init__(p)\n",
    "        self.factor = factor\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        # Random translation factor\n",
    "        tx = np.random.uniform(-self.factor, self.factor) * x.shape[0]\n",
    "        ty = np.random.uniform(-self.factor, self.factor) * x.shape[1]\n",
    "        # Affine transform, grayscale image so no need to transform channels\n",
    "        tform = AffineTransform(translation=(tx, ty))\n",
    "        # Apply transform, Image will be filled with zeros\n",
    "        # x = warp(x, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # y = warp(y, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # Batched warp\n",
    "        x = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in x])\n",
    "        y = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in y])\n",
    "        return x,y\n",
    "\n",
    "class Shear(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, factor: float = 0.5):\n",
    "        super().__init__(p)\n",
    "        self.factor = factor\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        # Random shear factor\n",
    "        shear_factor = np.random.uniform(-self.factor, self.factor)\n",
    "        # Create affine transform\n",
    "        tform = AffineTransform(shear=shear_factor)\n",
    "        # Use warp to apply transform\n",
    "        # x = warp(x, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # y = warp(y, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # Batched warp\n",
    "        x = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in x])\n",
    "        y = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in y])\n",
    "        return x,y\n",
    "class Augmentor:\n",
    "    \"\"\"\n",
    "    Augmentations:\n",
    "    flip_x: float\n",
    "        Probability of flipping the image horizontally\n",
    "    flip_y: float\n",
    "        Probability of flipping the image vertically\n",
    "    rotate: float\n",
    "        Probability of rotating the image\n",
    "    radians: float\n",
    "        Maximum rotation angle in radians\n",
    "    translate: float\n",
    "        Probability of translating the image\n",
    "    noise: float\n",
    "        Probability of adding noise to the image\n",
    "    noise_std: float\n",
    "        Standard deviation of the noise\n",
    "    noise_mean: float\n",
    "        Mean of the noise\n",
    "    mask: float\n",
    "        Probability of masking the image\n",
    "    max_n_masks: int\n",
    "        Maximum number of masks\n",
    "    mask_size: float\n",
    "        Maximum size of the mask as a fraction of the image size\n",
    "    shear: float\n",
    "        Probability of shearing the image\n",
    "    shear_factor: float\n",
    "        Maximum shear factor\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                flip_x:float=0.25,\n",
    "                flip_y:float=0.25,\n",
    "                rotate:float=0.5,\n",
    "                radians:float=np.pi/6,\n",
    "                translate:float=0.2,\n",
    "                noise:float=0.25,\n",
    "                noise_std:float=0.1,\n",
    "                noise_mean:float=0.1,\n",
    "                mask:float=0.8,\n",
    "                max_n_masks:int=10,\n",
    "                mask_size:float=0.25,\n",
    "                shear:float=0.1,\n",
    "                shear_factor:float=0.4,\n",
    "                verbose:bool=False\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        self._active = True\n",
    "        Augmentation.verbose = self.verbose\n",
    "        self.augmentations = {}\n",
    "        if noise > 0:\n",
    "            self.augmentations[\"noise\"] = Noise(p=noise, std=noise_std, mean=noise_mean)\n",
    "        if flip_x > 0:\n",
    "            self.augmentations[\"flip_x\"] = Flip(p=flip_x, axis=1)\n",
    "            # self.augmentations.append(Flip(p=flip_x, axis=1))\n",
    "        if flip_y > 0:\n",
    "            self.augmentations[\"flip_y\"] = Flip(p=flip_y, axis=0)\n",
    "            # self.augmentations.append(Flip(p=flip_y, axis=0))\n",
    "        if rotate > 0:\n",
    "            self.augmentations[\"rotate\"] = Rotate(p=rotate, angle=radians)\n",
    "            # self.augmentations.append(Rotate(p=rotate, angle=radians))\n",
    "        if translate > 0:\n",
    "            self.augmentations[\"translate\"] = Translate(p=translate, factor=translate)\n",
    "            # self.augmentations.append(Translate(p=translate, factor=translate))\n",
    "        if mask > 0:\n",
    "            self.augmentations[\"mask\"] = Mask(p=mask, max_n_masks=max_n_masks, mask_size=mask_size)\n",
    "            # self.augmentations.append(Mask(p=mask, max_n_masks=max_n_masks, mask_size=mask_size))\n",
    "        if shear > 0:\n",
    "            self.augmentations.append(Shear(p=shear, factor=shear_factor))\n",
    "    def __call__(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        if self._active:\n",
    "            if x.shape != y.shape:\n",
    "                raise Exception(\"x and y must have the same shape\")\n",
    "            if len(x.shape) < 4:\n",
    "                x = x[np.newaxis,...]\n",
    "                y = y[np.newaxis,...]\n",
    "            for aug in self.augmentations.values():\n",
    "                x,y = aug(x,y)\n",
    "        return x, y\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.augmentations.keys())\n",
    "    @property\n",
    "    def active(self):\n",
    "        return self._active\n",
    "    def scale_probability(self, key:str, factor:float):\n",
    "        if self.verbose:\n",
    "            print(f\"Scaling probability of {key} by {factor:3.3e}: {self.augmentations[key].p:3.3e} -> {self.augmentations[key].p * factor:3.3e}\")\n",
    "        self.augmentations[key].p *= factor\n",
    "    def set_active(self, active:bool):\n",
    "        self._active = active\n",
    "    def __repr__(self):\n",
    "        return f\"Augmentor({', '.join([f'{k}: {v.p:3.3e}' for k,v in self.augmentations.items()])})\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model(path):\n",
    "    m = keras.models.load_model(path)\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code.\n",
    "# learning_rate = 0.01\n",
    "# optim = optimizers.Adam(lr=learning_rate)\n",
    "# model.compile(loss=\"mse\",\n",
    "#               optimizer=optim)\n",
    "##\n",
    "\n",
    "\n",
    "custom_lr = 0.0001 #0.00005, Original. NOTE: I used 0.0005 for the first 50 Epochs.\n",
    "weight_decay = 0.01 # Weight decay for regularization.\n",
    "clipvalue = 2 # Clipvalue for regularization.\n",
    "augmentation_warmup = 0 # Warmup augmentations. How many epochs to train without augmentations.\n",
    "# NOTE: Might need to replace the keyword \"learning_rate\" with \"lr\" since i used an newer version of Keras, see code below.\n",
    "optim = Adam(learning_rate=custom_lr,decay=weight_decay,clipvalue=clipvalue)\n",
    "# custom_optimizer = Adam(lr=custom_lr,decay=weight_decay) # Replaced RMSprop for Adam.\n",
    "custom_loss = \"mse\" # MSE i used for regression. We'd like to predict categorically.\n",
    "custom_metric = \"mse\"\n",
    "augmentor = Augmentor(translate=0, # No translation. Due to lack of speed.\n",
    "                      shear=0, # No shear. Due to lack of speed.\n",
    "                      rotate=0, # No rotation. Due to lack of speed.\n",
    "                      mask=0.8, # Probability of masking the image.\n",
    "                      mask_size=0.2, # Maximum size of the mask as a fraction of the image size.\n",
    "                      max_n_masks=8, # Maximum number of masks to apply.\n",
    "                      noise=0.4, # Probability of adding Gaussian noise to the image.\n",
    "                      noise_mean=0.05, # Mean of the noise.\n",
    "                      noise_std=0.1, # Standard deviation of the noise.\n",
    "                      ) # Augmentation of the data.\n",
    "if augmentation_warmup > 0:\n",
    "    augmentor.set_active(False)\n",
    "model.compile(loss=custom_loss,\n",
    "              optimizer=optim,\n",
    "              metrics=[custom_metric])\n",
    "name = \"test_unet_upsampling_finetuned\"\n",
    "# Create model directory.\n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")\n",
    "model_dir = os.path.join(\"./models\", name)\n",
    "n_epochs = 50\n",
    "# NOTE: Are you satisfied with the optimizer and its parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da842fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot():\n",
    "    x_train, y_train = gen_train[0]\n",
    "    x_train, y_train = augmentor(x_train,y_train)\n",
    "    x_val, y_val = gen_val[0]\n",
    "    plot_sample(x_train, y_train,title=\"Augmented samples\")\n",
    "    plot_sample(x_val, y_val,title=\"Validation samples\")\n",
    "    # Plot initial predictions.\n",
    "    pred = model.predict(x_val)\n",
    "    plot_sample(x_val, pred,title=\"Initial predictions\")\n",
    "    print(\"Max value in prediction: \", np.min(pred))\n",
    "#plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34488f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best = np.inf\n",
    "batches = len(gen_train)\n",
    "total_batches = batches * n_epochs # Every batch is a training step.\n",
    "# Define the history arrays for speed.\n",
    "train_epoch_history = np.zeros(n_epochs)\n",
    "valid_epoch_history = np.zeros(n_epochs)\n",
    "train_batch_history = np.zeros(total_batches)\n",
    "counter = 0\n",
    "h = 0 # Initial loss for progress bar.\n",
    "\n",
    "augmentation_start = batches*augmentation_warmup\n",
    "print(\"Start training... This may take a while.\")\n",
    "for epoch in range(n_epochs):\n",
    "    validating_loss = []\n",
    "    pbar = tqdm(enumerate(gen_train)) # Progess bar to make it less boring, and trackable.\n",
    "    for idx, (t1, t2) in pbar:\n",
    "        t1, t2 = augmentor(t1,t2) # Augment the data.\n",
    "        h = model.train_on_batch(t1, t2)[0]\n",
    "        train_batch_history[counter] = h\n",
    "        counter += 1\n",
    "        if counter > augmentation_start and not augmentor.active:\n",
    "            augmentor.set_active(True)\n",
    "        if (idx+1)%10==0 or idx==0:\n",
    "            pbar.set_description(f\"Training Epoch {epoch+1}/{n_epochs}. {idx+1}/{batches} Batch. Training Loss MSE: {h:.3e}\")\n",
    "    for idx, (t1, t2) in enumerate(gen_val):\n",
    "        validating_loss.append(model.test_on_batch(t1, t2)[0])\n",
    "    train_epoch_history[epoch] = np.mean(train_batch_history[epoch*batches:(epoch+1)*batches])\n",
    "    valid_epoch_history[epoch] = np.mean(validating_loss)\n",
    "    if valid_epoch_history[epoch] < best:\n",
    "        best = valid_epoch_history[epoch]\n",
    "        model.save(model_dir)\n",
    "    print(f\"Epoch: {epoch + 1:2d}. Average loss - Training: {train_epoch_history[epoch]:.3e}, Validation: {valid_epoch_history[epoch]:.3e}\")\n",
    "# NOTE: Plotting the losses helps a lot.\n",
    "# NOTE: What does plotting the training data tell you? Should you plot something else?\n",
    "# NOTE: What should one do with the validation data? The data generator has a 'validation_data' argument as well.\n",
    "# NOTE: When should one stop? Did you overtrain? Did you train for long enough?\n",
    "# NOTE: Think abouct implementing Early Stopping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49814684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the losses.\n",
    "# Plot in separate window.\n",
    "epoch_to_batch = np.arange(0, total_batches, batches)\n",
    "%matplotlib qt\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epoch_to_batch, train_epoch_history, label=\"Training Loss\",color=\"C0\")\n",
    "plt.plot(train_batch_history, label=\"Training Loss per Batch\",alpha=0.5, color=\"C0\")\n",
    "# Center the plot around the epoch_to_batch.\n",
    "# plt.xlim(epoch_to_batch[0], epoch_to_batch[-1])\n",
    "plt.ylim(np.min(train_batch_history), np.max(train_epoch_history))\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss - MSE\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epoch_to_batch, valid_epoch_history, label=\"Validation Loss\",color=\"C1\")\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss - MSE\")\n",
    "# Increase spacing between subplots.\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()\n",
    "# Bottom two plots as one plot.\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epoch_to_batch, train_epoch_history, label=\"Training Loss\",color=\"C0\")\n",
    "plt.plot(epoch_to_batch, valid_epoch_history, label=\"Validation Loss\",color=\"C1\")\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss - MSE\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: Model, gen_data: DataGenerator,n: int = batch_size,augmentor: Augmentor = None):\n",
    "    t1, t2 = gen_data[np.random.randint(0, len(gen_data))]\n",
    "    if augmentor is not None:\n",
    "        t1, t2 = augmentor(t1, t2)\n",
    "    prediction = model.predict(t1)\n",
    "    cols = 3\n",
    "    plt.figure(figsize=(16, 10* n))\n",
    "    for idx in range(n):\n",
    "        plt.subplot(n, 3, idx * cols + 1)\n",
    "        plt.imshow(t1[idx, :, :], cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.title('INPUT')\n",
    "        # No axis labels.\n",
    "        plt.xticks([])\n",
    "        plt.subplot(n, 3, idx * cols + 2)\n",
    "        plt.imshow(t2[idx, :, :], cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.title('GT')\n",
    "        plt.xticks([])\n",
    "\n",
    "        plt.subplot(n, 3, idx * cols + 3)\n",
    "        plt.imshow(prediction[idx, :, :], cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.title('PRED')\n",
    "        plt.xticks([])\n",
    "        # Plot difference\n",
    "        # Print difference\n",
    "        print(f\"MSE: {np.mean((t2[idx, :, :] - prediction[idx, :, :])**2):.3e}\")\n",
    "    plt.show()\n",
    "        \n",
    "    print(f\"Average:{np.mean((t2 - prediction)**2):.3e}\")\n",
    "    # NOTE: What do the predictions mean? What values do they take on?\n",
    "%matplotlib qt\n",
    "test_model(best_model, gen_train,2)#,augmentor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b12c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the encoder part of the model.\n",
    "# encoder = Model(model.input, model.get_layer('input_2').output)\n",
    "encoder = Model(model.get_layer('Encoder').input,model.get_layer('Encoder').output)\n",
    "decoder = Model(model.get_layer('Decoder').input,model.get_layer('Decoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_encodings_grid(encodings: List[np.ndarray]):\n",
    "    n_encodings = len(encodings)\n",
    "    print(f\"Number of encodings: {n_encodings}\")\n",
    "    # Create a grid of images.\n",
    "    for encoding_layer in encodings:\n",
    "        # n_encodings different encodings.\n",
    "        # Each encoding has n_channels different channels. The figure will have sqrt(n_channels) rows and columns.\n",
    "        n_channels = encoding_layer.shape[-1]\n",
    "        rows = int(np.ceil((np.sqrt(n_channels))))\n",
    "        cols = int(np.ceil((np.sqrt(n_channels))))\n",
    "        print(f\"Number of channels: {n_channels}. Rows: {rows}. Cols: {cols}.\")\n",
    "        # Create a figure with the correct number of subplots.\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        grid = ImageGrid(fig, 111,\n",
    "                         nrows_ncols=(rows, cols), \n",
    "                         axes_pad=0.0,\n",
    "                         )\n",
    "        # Plot each channel.\n",
    "        for idx, ax in zip(range(n_channels),grid):\n",
    "            # Plot the channel.\n",
    "            ax.imshow(encoding_layer[:, :, idx], cmap='gray')\n",
    "            # No axis labels.\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # Set the title.\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da353294",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = gen_val[0]\n",
    "encodings_batched = encoder.predict(x_val)\n",
    "decoded = decoder.predict(encodings_batched[::-1])\n",
    "encodings = [enc[0] for enc in encodings_batched]\n",
    "plot_encodings_grid([encodings[-1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
