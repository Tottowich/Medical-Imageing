{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1aa4eab",
   "metadata": {},
   "source": [
    "# Assingment 2 - Contrast transfer\n",
    "### Course: Convolutional Neural Networks with Applications in Medical Image Analysis\n",
    "\n",
    "For the second assignment we will use the same dataset as before! Previously you have classified the available contrasts of the same anatomy, and for this assignment you will train an image to image model to generate one contrast from another. The task is to take T1-weighted images as inputs, and generate the corresponding T2-weighted images.\n",
    "\n",
    "Your tasks, to include in the Jupyter notebook you hand in, are:\n",
    "- Reach a validation MSE below 0.015 on the validation set, and describe what parameter combinations you have gone through to reach those results.\n",
    "- Describe the effect of each hyper-parameter you have changed, and the way you have experimented with them. What problems did you face? What happened when the training failed? Try describing everything that you have learnt.\n",
    "- Answer the questions set in notes\n",
    "\n",
    "Upload the updated notebook to canvas, that also contains your answers to the questions above. The deadline for the assignment is March $30^{th}$, 15:00.\n",
    "\n",
    "Good luck and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(2023)  # Set seed for reproducibility\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2023)\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(f\"GPU(s) available (using '{gpus[0].name}'). Training will be lightning fast!\")\n",
    "else:\n",
    "    print(\"No GPU(s) available. Training will be suuuuper slow!\")\n",
    "\n",
    "# NOTE: These are the packages you will need for the assignment.\n",
    "# NOTE: You are encouraged to use the course virtual environment, which already has GPU support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c238ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 arrays,\n",
    "                 batch_size=32,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.arrays = arrays\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        self.file_idx = 0\n",
    "        self.file_list = [self.data_path + '/' + s for s in\n",
    "                          os.listdir(self.data_path)]\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        with np.load(self.file_list[0]) as npzfile:\n",
    "            self.in_dims = []\n",
    "            self.n_channels = 1\n",
    "            for i in range(len(self.arrays)):\n",
    "                im = npzfile[self.arrays[i]]\n",
    "                self.in_dims.append((self.batch_size,\n",
    "                                    *np.shape(im),\n",
    "                                    self.n_channels))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.floor((len(self.file_list)) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                               self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.file_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        a = self.__data_generation(list_IDs_temp)\n",
    "        return a\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indexes after each epoch.\"\"\"\n",
    "        self.indexes = np.arange(len(self.file_list))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    #@threadsafe_generator\n",
    "    def __data_generation(self, temp_list):\n",
    "        \"\"\"Generate data containing batch_size samples.\"\"\"\n",
    "        # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        arrays = []\n",
    "\n",
    "        for i in range(len(self.arrays)):\n",
    "            arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n",
    "\n",
    "        for i, ID in enumerate(temp_list):\n",
    "            with np.load(ID) as npzfile:\n",
    "                for idx in range(len(self.arrays)):\n",
    "                    x = npzfile[self.arrays[idx]] \\\n",
    "                        .astype(np.single)\n",
    "                    x = np.expand_dims(x, axis=2)\n",
    "                    arrays[idx][i, ] = x / np.max(x)\n",
    "\n",
    "        return arrays\n",
    "\n",
    "# NOTE: Don't change the data generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d606d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dir = '/import/software/3ra023/vt22/brats/data/' # Change if you have copied the data locally on your machine \n",
    "array_labels = ['t1', 't2']  # Available arrays are: 't1', 't1ce', 't2', 'flair', 'mask'.\n",
    "batch_size = 16\n",
    "\n",
    "gen_train = DataGenerator(data_path=gen_dir + 'training',\n",
    "                          arrays=array_labels,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "gen_val = DataGenerator(data_path=gen_dir + 'validating',\n",
    "                        arrays=array_labels,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "gen_test = DataGenerator(data_path=gen_dir + 'testing',\n",
    "                         arrays=array_labels,\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "# NOTE: What arrays are you using? You can use multiple contrasts as inputs, if you'd like.\n",
    "# NOTE: What batch size are you using? Should you use more? Or less?\n",
    "# NOTE: Are you using the correct generators for the correct task? Training for training and validating for validating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e81cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = gen_train[0]\n",
    "for inp in range(np.shape(imgs)[0]):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(imgs[inp][i, :, :, 0], cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.title('Image size: ' + str(np.shape(imgs[inp][i, :, :, 0])))\n",
    "        plt.tight_layout()\n",
    "    plt.suptitle('Array: ' + gen_train.arrays[inp])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick summary of the data:\n",
    "print(f\"Number of training images : {len(gen_train.file_list)}\")\n",
    "print(f\"Training batch size       : {gen_train.in_dims}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages important for building and training your model.\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import Flatten, Input\n",
    "from tensorflow.keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, UpSampling2D\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import Tensor\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "                                    Add, AveragePooling2D, Flatten, Dense, UpSampling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def build_model():\n",
    "    filt_size = 3\n",
    "    input1 = Input(shape=(128, 128, 1))\n",
    "\n",
    "    conv1 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(input1)\n",
    "    conv1 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filt_size * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv5 = Conv2D(filt_size * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(filt_size * 8, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
    "    conv6 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(filt_size * 4, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
    "    conv7 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(filt_size * 2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
    "    conv8 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(filt_size, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
    "    conv9 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation=\"exponential\")(conv9)\n",
    "\n",
    "    return Model(inputs=input1, outputs=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e24a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your model.\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# NOTE: Are the input sizes correct?\n",
    "# NOTE: Do you have the correct number of input images?\n",
    "# NOTE: Are the output sizes correct?\n",
    "# NOTE: Do you have the correct number of output images?\n",
    "# NOTE: What's the range of the output? Can you use an activation as a regularizer?\n",
    "# NOTE: Try to imagine the model layer-by-layer and think it through. Is it doing something reasonable?\n",
    "# NOTE: Are your parameters split evenly inside the model? Try making \"too large\" layers smaller\n",
    "# NOTE: Will the model fit into memory? Is the model too small? Is the model too large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optim = optimizers.Adam(lr=learning_rate)\n",
    "model.compile(loss=\"mse\",\n",
    "              optimizer=optim)\n",
    "\n",
    "# NOTE: Are you satisfied with the optimizer and its parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "print(\"Start training... This may take a while.\")\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss = []\n",
    "    validating_loss = []\n",
    "    \n",
    "    for idx, (t1, t2) in enumerate(gen_train):\n",
    "        h = model.train_on_batch(t1, t2)\n",
    "        training_loss.append(h)\n",
    "    \n",
    "    for idx, (t1, t2) in enumerate(gen_val):\n",
    "        validating_loss.append(model.test_on_batch(t1, t2))\n",
    "        \n",
    "    print(\"Epoch \" + str(epoch + 1) + \"/\" + str(n_epochs) + \". Mean validating loss: \" + str(np.mean(validating_loss)))\n",
    "\n",
    "# NOTE: Plotting the losses helps a lot.\n",
    "# NOTE: What does plotting the training data tell you? Should you plot something else?\n",
    "# NOTE: What should one do with the validation data? The data generator has a 'validation_data' argument as well.\n",
    "# NOTE: When should one stop? Did you overtrain? Did you train for long enough?\n",
    "# NOTE: Think about implementing Early Stopping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1, t2 = gen_val[np.random.randint(0, len(gen_val))]\n",
    "prediction = model.predict(t1)\n",
    "\n",
    "plt.figure(figsize=(8, 4 * batch_size))\n",
    "for idx in range(batch_size):\n",
    "    plt.subplot(batch_size, 2, idx * 2 + 1)\n",
    "    plt.imshow(t2[idx, :, :], cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.title('GT')\n",
    "    plt.subplot(batch_size, 2, idx * 2 + 2)\n",
    "    plt.imshow(prediction[idx, :, :], cmap='gray')\n",
    "    plt.colorbar()\n",
    "    plt.title('PRED')\n",
    "    \n",
    "print(np.mean((t2 - prediction)**2))\n",
    "# NOTE: What do the predictions mean? What values do they take on?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
