{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assingment 1 - MRI Contrast Classifier\n",
    "### Course: Convolutional Neural Networks with Applications in Medical Image Analysis\n",
    "\n",
    "\n",
    "Welcome to the first course assignments! We have collected a dataset based on the popular BraTS challenge (http://braintumorsegmentation.org/), containing MRI slices of the brain, of different contrasts (sometimes referred to as modalities): T1-weighted (T1w), T1-weighted with contrast agent (T1w-CE), T2-weighted (T2w), and FLAIR, also a manually segmented binary map of a tumor, if visible on the slice. \n",
    "\n",
    "The assignments will build on each other, and all three of them will use the same dataset and the same data generator so take your time to familiarize yourself with these.\n",
    "\n",
    "In the first assignments you are tasked with training a convolutional neural network to classify the acquired MR data into their contrasts (T1w, T1w-CE, T2w, FLAIR).\n",
    "\n",
    "The code below is a working, but poor implementation of classifying between T1w and T2w contrasts. Your exercise is to expand and improve the code so the final model handles all four contrasts, and achieves an accuracy of $95\\%$. \n",
    "\n",
    "The most important aspect of the assignment is that all your choices in the final code are explained and supported in writing. Show your though process, even if you have managed to improve the accuracy by trial and error. Make sure that in the report you include:\n",
    "- How you reached the required performances\n",
    "- Plot the confusion matrix of the validation data, using the final model.\n",
    "- Describe the thought process behind building your model and choosing the model hyper-parameters.\n",
    "- Describe what you think are the biggest issues with the current setup, and how to solve them.\n",
    "\n",
    "Upload the updated notebook to Canvas before February $16^{th}$, 15:00.\n",
    "\n",
    "Good luck and have fun!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment setup\n",
    "conda create --name 3ra023vt23 python=3.8.12\n",
    "- You now have an environment named “3ra023vt23”. Activate by:\n",
    "$ conda activate 3ra023vt23\n",
    "% Blank row\n",
    "\n",
    "- Install CUDA and cuDNN:\n",
    "conda install cudatoolkit=10.1.243 cudnn=7.6.5\n",
    "- Install Tensorflow **with GPU** support:\n",
    "conda install tensorflow-gpu=2.2.0\n",
    "- Or, install Tensorflow **without GPU** support:\n",
    "conda install tensorflow=2.2.0\n",
    "- Install the other packages we need:\n",
    "conda install jupyter=1.0.0\n",
    "conda install matplotlib=3.5.0\n",
    "conda install scikit-learn=1.0.2\n",
    "conda install scikit-image=0.18.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(2023)  # Set seed for reproducibility\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2023)\n",
    "!pip install tqdm # Adding tqdm to use progress bars. Unbarable waiting for each epoch to finish without feedback.\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(gpus) > 0:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(f\"GPU(s) available (using '{gpus[0].name}'). Training will be lightning fast!\")\n",
    "else:\n",
    "    print(\"No GPU(s) available. Training will be suuuuper slow!\")\n",
    "\n",
    "# NOTE: These are the packages you will need for the assignment.\n",
    "# NOTE: You are encouraged to use the course virtual environment, which already has GPU support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below will define the data generator for the data you will be using. You should not change anything in the below code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 arrays,\n",
    "                 batch_size=32,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.arrays = arrays\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        self.file_idx = 0\n",
    "        self.file_list = [self.data_path + '/' + s for s in\n",
    "                          os.listdir(self.data_path)]\n",
    "        self.on_epoch_end()\n",
    "        with np.load(self.file_list[0]) as npzfile:\n",
    "            self.in_dims = []\n",
    "            self.n_channels = 1\n",
    "            print(npzfile)\n",
    "            for i in range(len(self.arrays)):\n",
    "                im = npzfile[self.arrays[i]]\n",
    "                self.in_dims.append((self.batch_size,\n",
    "                                    *np.shape(im),\n",
    "                                    self.n_channels))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.floor((len(self.file_list)) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                               self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.file_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        a = self.__data_generation(list_IDs_temp)\n",
    "        return a\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indexes after each epoch.\"\"\"\n",
    "        self.indexes = np.arange(len(self.file_list))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    #@threadsafe_generator\n",
    "    def __data_generation(self, temp_list):\n",
    "        \"\"\"Generate data containing batch_size samples.\"\"\"\n",
    "        # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        arrays = []\n",
    "\n",
    "        for i in range(len(self.arrays)):\n",
    "            arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n",
    "\n",
    "        for i, ID in enumerate(temp_list):\n",
    "            with np.load(ID) as npzfile:\n",
    "                for idx in range(len(self.arrays)):\n",
    "                    x = npzfile[self.arrays[idx]] \\\n",
    "                        .astype(np.single)\n",
    "                    x = np.expand_dims(x, axis=2)\n",
    "                    arrays[idx][i, ] = x\n",
    "\n",
    "        return arrays\n",
    "\n",
    "# NOTE: Don't change the data generator!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_dir = \"../data/\"  # Change if you have copied the data locally on your machine\n",
    "array_labels = ['t1', 't1ce', 't2', 'flair']  # Available arrays are: 't1', 't1ce', 't2', 'flair', 'mask'.\n",
    "N_CLASSES = len(array_labels)\n",
    "batch_size = 32\n",
    "\n",
    "gen_train = DataGenerator(data_path=gen_dir + 'training',\n",
    "                          arrays=array_labels,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "gen_val = DataGenerator(data_path=gen_dir + 'validating',\n",
    "                        arrays=array_labels,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "gen_test = DataGenerator(data_path=gen_dir + 'testing',\n",
    "                         arrays=array_labels,\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "# NOTE: What arrays are you using? Their order will be the same as their unpacking order during training!\n",
    "# NOTE: What batch size are you using? Should you use more? Or less?\n",
    "# NOTE: Are you using the correct generators for the correct task? Training for training and validating for validating?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot some example images from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = gen_train[0]\n",
    "for inp in range(np.shape(imgs)[0]):\n",
    "    plt.figure(figsize=(12,5))\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i + 1)\n",
    "        plt.imshow(imgs[inp][i, :, :, 0], cmap='gray')\n",
    "        plt.title('Image size: ' + str(np.shape(imgs[inp][i, :, :, 0])))\n",
    "        plt.tight_layout()\n",
    "    plt.suptitle('Array: ' + gen_train.arrays[inp])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dataset preprocessing so far has been to help you, you should not change anything above. However, from now on, take nothing for granted.\n",
    "\n",
    "A quick summery of the data sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A quick summary of the data:\n",
    "print(f\"Number of training images: {str(len(gen_train.file_list))}\")\n",
    "print(f\"Training batch size      : {str(gen_train.in_dims)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Flatten, Input\n",
    "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D, UpSampling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Concatenate\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, Nadam\n",
    "\n",
    "# NOTE: Take inspiration from the imported layers and components, however you are not required to use all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_model(height, width, channels):\n",
    "    inp = Input(shape=(height, width, channels), name='input_1')\n",
    "    drop_rate = 0.1 # 0.1 Small dropout throught the network.\n",
    "    conv1 = Conv2D(8, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal',use_bias=False)(inp)\n",
    "    #conv1 = BatchNormalization()(conv1) # During the first Training runs I had BN but worked without. \n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    pool1 = Dropout(drop_rate)(pool1)\n",
    "\n",
    "    conv2 = Conv2D(8, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal',use_bias=False)(pool1)\n",
    "    #conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(16, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    pool3 = Dropout(drop_rate)(pool3)\n",
    "    \n",
    "    conv4 = Conv2D(32, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    pool4 = Dropout(drop_rate)(pool4)\n",
    "    \n",
    "    conv5 = Conv2D(64, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal',use_bias=False)(pool4)\n",
    "    #conv5 = BatchNormalization()(conv5)\n",
    "    pool5 = MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "    pool5 = Dropout(drop_rate)(pool5)\n",
    "\n",
    "    conv6 = Conv2D(64, 3, activation=\"relu\", padding='same', kernel_initializer='he_normal')(pool5)\n",
    "    pool6 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "    \n",
    "    # Output layer to produce probabilities.\n",
    "    flat = Flatten()(pool6)\n",
    "    x = Dense(64, activation='relu')(flat)\n",
    "    output_1 = Dense(4, activation='softmax')(x)\n",
    "\n",
    "    return Model(inputs=[inp], outputs=[output_1])\n",
    "\n",
    "# NOTE: A better designed network will improve performance. Look at the imported layers in the cell above for inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "height, width, channels = gen_train.in_dims[0][1:]\n",
    "model = build_model(height=height, width=width, channels=channels)\n",
    "#model = build_resnet(height=height, width=width, channels=channels)\n",
    "\n",
    "#model = build_improved_model()\n",
    "model.summary()\n",
    "\n",
    "# NOTE: Are the input sizes correct?\n",
    "# NOTE: Are the output sizes correct?\n",
    "# NOTE: Try to imagine the model layer-by-layer and think it through. Is it doing something reasonable?\n",
    "# NOTE: Are the model parameters split \"evenly\" between the layers? Or is there one huge layer?\n",
    "# NOTE: Will the model fit into memory? Is the model too small? Is the model too large?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    m = keras.models.load_model(path)\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "custom_lr = 0.01 # 0.00005, Original. I used 0.001 for the first 20 Epochs to more quickly converge.\n",
    "                  # It was then set to 0.0001 while finetuning.\n",
    "weight_decay = 0.0 # No weight decay initialy. Increased to 0.02 to finetune.\n",
    "custom_optimizer = Adam(lr=custom_lr,weight_decay=weight_decay) # Replaced RMSprop for Adam.\n",
    "custom_loss = \"categorical_crossentropy\" # MSE i used for regression. We'd like to predict categorically.\n",
    "custom_metric = \"accuracy\"\n",
    "#path = \"./models/Axtorp_finetuned\"\n",
    "#model = load_model(path) # When used when finetuning the model.\n",
    "model.compile(loss=custom_loss,\n",
    "              optimizer=custom_optimizer,\n",
    "              metrics=[custom_metric])\n",
    "name = \"test\"\n",
    "n_epochs = 20\n",
    "n_classes = N_CLASSES\n",
    "# Labels:\n",
    "t1_label = tf.one_hot(np.repeat(0, batch_size), n_classes)\n",
    "t1ce_label = tf.one_hot(np.repeat(1, batch_size), n_classes)\n",
    "t2_label = tf.one_hot(np.repeat(2, batch_size), n_classes)\n",
    "flair_label = tf.one_hot(np.repeat(3, batch_size), n_classes)\n",
    "\n",
    "# NOTE: Are you satisfied with the loss function?\n",
    "# NOTE: Are you satisfied with the metric?\n",
    "# NOTE: Are you satisfied with the optimizer? Look at the cell where the optimizers are imported for inspiration.\n",
    "# NOTE: Are you satisfied with the optimizer's parameters?\n",
    "\n",
    "# How the model was designed.\n",
    "# 1. The architecture was inspired by classical encoder backbones.\n",
    "# 2. I started by training an unregularized model to overfit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import TrainingRun\n",
    "# def __init__(self, \n",
    "#                 model:Model,\n",
    "#                 epochs:int=1,\n",
    "#                 model_path:str=None,\n",
    "#                 optimizer:Optimizer=None,\n",
    "#                 train_generator:DataGenerator=None,\n",
    "#                 val_generator:DataGenerator=None,\n",
    "#                 test_generator:DataGenerator=None,\n",
    "#                 augmentor:Augmentor=None,\n",
    "#                 save_interval:int=1,\n",
    "#                 tensorboard_callback:tb=None,):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainingRun(model, n_epochs, \"models/Test\", custom_optimizer,gen_train, gen_val, gen_test)\n",
    "trainer.open_tensorboard()\n",
    "trainer.train_classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design.\n",
    "I wanted to keep the model as small as possible while achiving the required accuracy of $95\\%$. This was done by increasing the **depth** while keeping the output **MLP as small as possible** since it gives arise a large amount of complexity.\n",
    "### Inspiration\n",
    "The model was inspired by a simple encoder backbone with a feature extracting CNN reducing dimensionality before a final Multi Layer Perceptron concluded with a softmax activation to produce probability outputs. The CNN extracts important features from the images and summarizes the images in a feature vector which is passed to the output layer.\n",
    "### Design proces\n",
    "\n",
    "1. Overfit the data using a complex unregularized model with a large amount of filters per layer.\n",
    "2. Reduce the complexity by decreasing the amount of filters while retaining depth.\n",
    "3. When the variance of the model decreases. Slowly increase regularization to find a balance between complexity and variance.\n",
    "Initialy the model included roughyl 900k parameters with a similar architecture as the final product only with more filters per convolutional layer and a deeper MLP as output.\n",
    "The model size was quickly reduced upon iteration seeing as the model would quickly overfit the dataset at this size and depth. At first the model included BatchNormalization layer. These were later removed as the did not make a large difference. This should probably be reassed as the model without normalization layers probably induce large amount of variance throught the layers.\n",
    "\n",
    "When the model size had been reduced it was necessary to include **Dropout** to regularize the model while retaining a high accuracy. This was done by including several dropout layers throughout the layers to make the layers more robust and less fixated on certain pixel values or activations.\n",
    "\n",
    "\n",
    "\n",
    "## Metrics\n",
    "The only metric used was the accuracy since the task stated that it was the sought after metric.\n",
    "It could be useful to look at other metrics such as recall, precision and f1-score to get an idea of how the data/data augmentation should be altered. However since we only focus model creation part during this assignment, I deemed it not to be necessary.\n",
    "## Loss function\n",
    "I used **Categorical Crossentropy Loss** as a loss function. This is one of the most common loss functions used for classification and works intuitively well with a **Softmax** activation in the final output layer.\n",
    "\n",
    "## Training procees.\n",
    "\n",
    "When training the larger models as described under **Design Process** the learning rate set to $0.001$. I then tracked the training vs validation accuracy to see if the model would quickly overfit or if it the metrics properties would converge simultaneously. When achieving a relativly high accuracy on the validation set along a plateaued training loss value I decreased the learning rate to $0.0001$ and increased weight decay to $0.02$.\n",
    "\n",
    "# Results\n",
    "## Accuracy\n",
    "\n",
    "| Data       | Accuracy (%) |\n",
    "|------------|--------------|\n",
    "| Train:     | 99.579       |\n",
    "| Validation:| 96.312       |\n",
    "| Test:      | 96.020       |\n",
    "\n",
    "As seen in the table there is still a destinct difference between training accuracy and test accuracy. This should be addressed to further increase the test-set performance and improve the generalizability of the model.\n",
    "\n",
    "## Improvements\n",
    "### Training improvements\n",
    "The results above could be improved by further increasing regularization terms such as Dropout, weight decay or implementing data augmentation. It could also be beneficial to implement a learning rate scheduler to vary the learning rate adaptively.\n",
    "### Model improvements\n",
    "The performance of the model could also be improved by adding skip-connections which has shown to be effective in classification tasks as seen in **ResNet** architectures widley used in classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best = 0\n",
    "batches = len(gen_train)\n",
    "# Training Scheme\n",
    "h = [1000,0] # Initial loss for progress bar.\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss = [] # Track loss per epoch.\n",
    "    validating_loss = []\n",
    "    pbar = tqdm(enumerate(gen_train)) # Progess bar to make it less boring, and trackable.\n",
    "    # Training data\n",
    "    for idx, (t1, t1ce,t2,flair) in pbar:\n",
    "        if (idx+1)%10==0:\n",
    "            pbar.set_description(f\"Training Epoch {epoch+1}/{n_epochs}. {idx+1}/{batches} Batch. Training Loss: {h[0]:.3e}, Accuracy: {h[1]:.3e}\")\n",
    "        labels = np.concatenate((t1_label,t1ce_label,t2_label, flair_label), axis=0)\n",
    "        images = np.concatenate((t1, t1ce, t2, flair), axis=0)\n",
    "        h = model.train_on_batch(images, labels)\n",
    "        training_loss.append(h)\n",
    "        \n",
    "    train_vals = np.array(training_loss) # Convert to numpy for faster computation.\n",
    "    ave_train_loss = train_vals[:,0].mean() # Get average loss and accuracy over the epoch.\n",
    "    ave_train_acc =  train_vals[:,1].mean()\n",
    "    pbar.set_description(f\"Training Epoch {epoch+1}/{n_epochs}. {idx+1}/{len(gen_train)} Batches. Training Loss: {ave_train_loss:.3e}, Accuracy: {ave_train_acc:.3e}\")\n",
    "    # Validation data\n",
    "    for idx, (t1, t1ce,t2,flair) in enumerate(gen_val):\n",
    "        images = np.concatenate((t1, t1ce, t2, flair), axis=0)\n",
    "        validating_loss.append(model.test_on_batch(images, labels)[-1])\n",
    "    if np.mean(validating_loss)>best and best > 0.8:\n",
    "        model.save(\"models/\"+name)\n",
    "            \n",
    "    print(f\"Epoch: {epoch + 1:2d}. Average accuracy - Training: {ave_train_acc:.3e}, Validation: {np.mean(validating_loss):.3e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code cell above demonstrates the training process with a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "def mean_average_accuracy(cm):\n",
    "    return np.diag(cm).mean()\n",
    "# Confusion matrix without using sklearn package.\n",
    "def confusion_matrix(model,gen_data, name=\"\",break_point:int=None):\n",
    "    # Track predictions vs labels.\n",
    "    #preds = []\n",
    "    #ls = []\n",
    "    cm = np.zeros((4,4)) # Initialize the confusion matrix.\n",
    "    labels = np.concatenate((t1_label,t1ce_label,t2_label, flair_label), axis=0) # Create batched label.\n",
    "    for idx, (t1, t1ce,t2,flair) in enumerate(gen_data):\n",
    "        images = np.concatenate((t1, t1ce, t2, flair), axis=0) # Batch images.\n",
    "        #ls.append(labels.argmax(1).flatten()) # Add the seen labels to track metrics.\n",
    "        pred = model.predict_on_batch(images).argmax(1)\n",
    "        #preds.append(pred.flatten())\n",
    "        for l,p in zip(labels.argmax(1),pred):\n",
    "            cm[l,p] += 1 # Count number of guesses per class.\n",
    "        if break_point and idx>=break_point-1:\n",
    "            break\n",
    "    cm = cm/cm.sum(0) # Normalize along prediced channel.\n",
    "    #result = confusion_matrix(np.array(ls).flatten(), np.array(preds).flatten() , normalize='pred')\n",
    "    cm_display = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = array_labels)\n",
    "    cm_display.plot()\n",
    "    cm_display.im_.figure.suptitle(name)\n",
    "    plt.plot()\n",
    "    print(f\"Accuracy - {name}: {np.diag(cm).mean()*100:.3f}%\")\n",
    "    return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    train_preds,train_labels,cm_train,cm_disp_train = confusion_matrix(model,gen_train,\"Train\",len(gen_val))\n",
    "    val_preds,val_labels,cm_val,cm_disp_val = confusion_matrix(model,gen_val,\"Validation\")\n",
    "    test_preds,test_labels,cm_test,cm_disp_test = confusion_matrix(model,gen_test,\"Test\")\n",
    "def load_model(path):\n",
    "    m = keras.models.load_model(path)\n",
    "    print(m.summary())\n",
    "    return m\n",
    "final_model = load_model(\"models/Axtorp_finetuned\")\n",
    "test_model(final_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "b943d0b5534f5ef85c0420b5997dcb3cb706b77c7855306dea748f7a63e44caf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
