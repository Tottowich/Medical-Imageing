{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1aa4eab",
   "metadata": {},
   "source": [
    "# Assingment 2 - Contrast transfer\n",
    "### Course: Convolutional Neural Networks with Applications in Medical Image Analysis\n",
    "\n",
    "For the second assignment we will use the same dataset as before! Previously you have classified the available contrasts of the same anatomy, and for this assignment you will train an image to image model to generate one contrast from another. The task is to take T1-weighted images as inputs, and generate the corresponding T2-weighted images.\n",
    "\n",
    "Your tasks, to include in the Jupyter notebook you hand in, are:\n",
    "- Reach a validation MSE below 0.015 on the validation set, and describe what parameter combinations you have gone through to reach those results.\n",
    "- Describe the effect of each hyper-parameter you have changed, and the way you have experimented with them. What problems did you face? What happened when the training failed? Try describing everything that you have learnt.\n",
    "- Answer the questions set in notes\n",
    "\n",
    "Upload the updated notebook to canvas, that also contains your answers to the questions above. The deadline for the assignment is March $30^{th}$, 15:00.\n",
    "\n",
    "Good luck and have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc435e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(2023)  # Set seed for reproducibility\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "tf.random.set_seed(2026) # Note: Different to test different initializations.\n",
    "!pip install tqdm # Adding tqdm to use progress bars. Unbarable waiting for each epoch to finish without feedback.\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e57cf7dc",
   "metadata": {},
   "source": [
    "## GPU verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb49a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import img_to_array\n",
    "from keras.utils import load_img\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Using ImageGrid to plot the encodings.\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from typing import List\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "available = len(gpus) > 0\n",
    "if available:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print(f\"GPU(s) available (using '{gpus[0].name}'). Training will be lightning fast!\")\n",
    "    # Run some dummy code to initialize the GPU.\n",
    "    rand = tf.random.uniform((100, 100))\n",
    "    _ = tf.matmul(rand, rand)\n",
    "else:\n",
    "    print(\"No GPU(s) available. Training will be suuuuper slow!\")\n",
    "\n",
    "# NOTE: These are the packages you will need for the assignment.\n",
    "# NOTE: You are encouraged to use the course virtual environment, which already has GPU support."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f077c2b",
   "metadata": {},
   "source": [
    "## Data Generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c238ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 arrays,\n",
    "                 batch_size=32,\n",
    "                 ):\n",
    "\n",
    "        self.data_path = data_path\n",
    "        self.arrays = arrays\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if data_path is None:\n",
    "            raise ValueError('The data path is not defined.')\n",
    "\n",
    "        if not os.path.isdir(data_path):\n",
    "            raise ValueError('The data path is incorrectly defined.')\n",
    "\n",
    "        self.file_idx = 0\n",
    "        self.file_list = [self.data_path + '/' + s for s in\n",
    "                          os.listdir(self.data_path)]\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        with np.load(self.file_list[0]) as npzfile:\n",
    "            self.in_dims = []\n",
    "            self.n_channels = 1\n",
    "            for i in range(len(self.arrays)):\n",
    "                im = npzfile[self.arrays[i]]\n",
    "                self.in_dims.append((self.batch_size,\n",
    "                                    *np.shape(im),\n",
    "                                    self.n_channels))\n",
    "        # Empty initialization array\n",
    "        arrays = []\n",
    "        for i in range(len(self.arrays)):\n",
    "            arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n",
    "        self.init_arrays = arrays\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Get the number of batches per epoch.\"\"\"\n",
    "        return int(np.floor((len(self.file_list)) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generate one batch of data.\"\"\"\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index * self.batch_size:(index + 1) *\n",
    "                               self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [self.file_list[k] for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        a = self.__data_generation(list_IDs_temp)\n",
    "        return a\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Update indexes after each epoch.\"\"\"\n",
    "        self.indexes = np.arange(len(self.file_list))\n",
    "        np.random.shuffle(self.indexes)\n",
    "    \n",
    "    #@threadsafe_generator\n",
    "    def __data_generation(self, temp_list):\n",
    "        \"\"\"Generate data containing batch_size samples.\"\"\"\n",
    "        # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        arrays = self.init_arrays\n",
    "\n",
    "        # for i in range(len(self.arrays)):\n",
    "        #     arrays.append(np.empty(self.in_dims[i]).astype(np.single))\n",
    "\n",
    "        for i, ID in enumerate(temp_list):\n",
    "            with np.load(ID) as npzfile:\n",
    "                for idx in range(len(self.arrays)):\n",
    "                    x = npzfile[self.arrays[idx]] \\\n",
    "                        .astype(np.single)\n",
    "                    x = np.expand_dims(x, axis=2)\n",
    "                    # Check if any nan\n",
    "                    x_max = np.max(x)\n",
    "                    if x_max == 0:\n",
    "                        arrays[idx][i, ] = x\n",
    "                    else:\n",
    "                        arrays[idx][i, ] = x / x_max\n",
    "\n",
    "        return arrays\n",
    "\n",
    "# NOTE: Don't change the data generator!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d210287",
   "metadata": {},
   "source": [
    "### Data Generators creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d606d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_dir = './data_zip/' # Change if you have copied the data locally on your machine \n",
    "array_labels = ['t1', 't1ce', 't2', 'flair','mask']  # Available arrays are: 't1', 't1ce', 't2', 'flair', 'mask'.\n",
    "per_batch = len(array_labels)-1 # We don't want to use the mask as an input.\n",
    "batch_size = 16\n",
    "\n",
    "batch_size = batch_size//per_batch \n",
    "\n",
    "gen_train = DataGenerator(data_path=gen_dir + 'training',\n",
    "                          arrays=array_labels,\n",
    "                          batch_size=batch_size)\n",
    "\n",
    "gen_val = DataGenerator(data_path=gen_dir + 'validating',\n",
    "                        arrays=array_labels,\n",
    "                        batch_size=batch_size)\n",
    "\n",
    "gen_test = DataGenerator(data_path=gen_dir + 'testing',\n",
    "                         arrays=array_labels,\n",
    "                         batch_size=batch_size)\n",
    "\n",
    "# NOTE: What arrays are you using? You can use multiple contrasts as inputs, if you'd like.\n",
    "# NOTE: What batch size are you using? Should you use more? Or less?\n",
    "# NOTE: Are you using the correct generators for the correct task? Training for training and validating for validating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for nan in masks:\n",
    "nan_count = 0\n",
    "for batch in tqdm(gen_train):\n",
    "    mask = batch[-1]\n",
    "    for i in range(mask.shape[0]):\n",
    "        if np.isnan(mask[i]).any():\n",
    "            # Count how many nan values are in the mask.\n",
    "            nan_count += 1\n",
    "print(f\"Found {nan_count}/{len(gen_train)*batch_size} batches with nan in the mask.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fceacc47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7378fa07",
   "metadata": {},
   "source": [
    "## Plot examples of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6575d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A quick summary of the data:\n",
    "print(f\"Number of training images : {len(gen_train.file_list)}\")\n",
    "print(f\"Training batch size       : {gen_train.in_dims}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb5d9723",
   "metadata": {},
   "source": [
    "## Keras Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ebe0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages important for building and training your model.\n",
    "# import keras\n",
    "from keras import backend as K\n",
    "from keras import mixed_precision\n",
    "from keras import optimizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import Flatten, Input\n",
    "from keras.layers import MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, concatenate\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Dropout, UpSampling2D\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam, RMSprop, Nadam\n",
    "# Dice coefficient loss function\n",
    "from keras.losses import binary_focal_crossentropy, BinaryFocalCrossentropy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60ae6979",
   "metadata": {},
   "source": [
    "## Provided model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921a3410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model provided by the supervisors\n",
    "from tensorflow import Tensor\n",
    "from keras.layers import Input, Conv2D, ReLU, BatchNormalization, \\\n",
    "                        Add, AveragePooling2D, Flatten, Dense, UpSampling2D\n",
    "from keras.models import Model\n",
    "\n",
    "def build_model():\n",
    "    filt_size = 8\n",
    "    # input1 = Input(shape=(128, 128, 1))\n",
    "    input1 = Input(shape=(256, 256, 1))\n",
    "\n",
    "    conv1 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(input1)\n",
    "    conv1 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(filt_size * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal',name=\"bottle_neck1\")(pool4)\n",
    "    conv5 = Conv2D(filt_size * 16, 3, activation='relu', padding='same', kernel_initializer='he_normal',name=\"bottle_neck2\")(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    skip46 = Conv2D(filt_size * 8, 1, activation='relu', padding='same', kernel_initializer='he_normal',name=\"skip4-6\")(conv4)\n",
    "    up6 = Conv2D(filt_size * 8, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
    "    merge6 = concatenate([drop4, up6], axis=3)\n",
    "    conv6 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6) + skip46\n",
    "    conv6 = Conv2D(filt_size * 8, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
    "\n",
    "    skip37 = Conv2D(filt_size * 4, 1, activation='relu', padding='same', kernel_initializer='he_normal',name=\"skip3-7\")(conv3)\n",
    "    up7 = Conv2D(filt_size * 4, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge7 = concatenate([conv3, up7], axis=3)\n",
    "    conv7 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7) + skip37\n",
    "    conv7 = Conv2D(filt_size * 4, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
    "\n",
    "    skip28 = Conv2D(filt_size * 2, 1, activation='relu', padding='same', kernel_initializer='he_normal',name=\"skip2-8\")(conv2)\n",
    "    up8 = Conv2D(filt_size * 2, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n",
    "    merge8 = concatenate([conv2, up8], axis=3)\n",
    "    conv8 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8) + skip28\n",
    "    conv8 = Conv2D(filt_size * 2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
    "\n",
    "    skip19 = Conv2D(filt_size, 1, activation='relu', padding='same', kernel_initializer='he_normal',name=\"skip1-9\")(conv1)\n",
    "    up9 = Conv2D(filt_size, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge9 = concatenate([conv1, up9], axis=3)\n",
    "    conv9 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9) + skip19\n",
    "    conv9 = Conv2D(filt_size, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation=\"sigmoid\",name=\"prediction\")(conv9)\n",
    "\n",
    "    return Model(inputs=input1, outputs=conv10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308bb577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "from archs.segmentation.unet import build_unet\n",
    "W,H,C = 256,256,1\n",
    "input_shape = (W,H,C)\n",
    "num_classes = C # Number of classes is equal to the number of channels in the output\n",
    "filters = [8,16,32,64,128,256,512,1024]\n",
    "kernel_size = [3,3,3,3,3,3,3,1]\n",
    "strides = 1\n",
    "padding = \"same\"\n",
    "activation = \"selu\"\n",
    "# drop_rate_encoder = [0.01,0.02,0.02,0.1]\n",
    "# drop_rate_decoder = [0.01,0.1,0.1,0]\n",
    "drop_rate_encoder = [0.0,0.02,0.02,0.05]\n",
    "drop_rate_decoder = [0.0]\n",
    "depth_encoder = [2,2,3,4,4,5,6,8]\n",
    "depth_decoder = [1,1,1,1,1,1,1,1]\n",
    "output_depth = 10\n",
    "output_activation = \"sigmoid\"\n",
    "\n",
    "model = build_unet(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes,\n",
    "    filters=filters,\n",
    "    kernel_size=kernel_size,\n",
    "    strides=strides,\n",
    "    padding=padding,\n",
    "    activation=activation,\n",
    "    depth_encoder=depth_encoder,\n",
    "    decoder_type=\"add\",\n",
    "    upsample_type=\"bilinear\",\n",
    "    depth_decoder=depth_decoder,\n",
    "    drop_rate_encoder=drop_rate_encoder,\n",
    "    drop_rate_decoder=drop_rate_decoder,\n",
    "    output_depth=output_depth,\n",
    "    output_activation=output_activation,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9504fae",
   "metadata": {},
   "source": [
    "### Important questions to answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e24a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build your model.\n",
    "# model = build_model()\n",
    "# model.summary()\n",
    "\n",
    "# NOTE: Are the input sizes correct?\n",
    "# NOTE: Do you have the correct number of input images?\n",
    "# NOTE: Are the output sizes correct?\n",
    "# NOTE: Do you have the correct number of output images?\n",
    "# NOTE: What's the range of the output? Can you use an activation as a regularizer?\n",
    "# NOTE: Try to imagine the model layer-by-layer and think it through. Is it doing something reasonable?\n",
    "# NOTE: Are your parameters split evenly inside the model? Try making \"too large\" layers smaller\n",
    "# NOTE: Will the model fit into memory? Is the model too small? Is the model too large?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3ef2c975",
   "metadata": {},
   "source": [
    "## Augmentation class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ca9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation class for used in the training pipeline.\n",
    "# float wrapper for probability\n",
    "def prob(p: float) -> bool:\n",
    "    return np.random.random() < p\n",
    "class Augmentation:\n",
    "    verbose: bool = False\n",
    "    # Parent class for all augmentations\n",
    "    def __init__(self, p: float):\n",
    "        self.p = p\n",
    "    @property\n",
    "    def name(self) -> str:\n",
    "        return self.__class__.__name__\n",
    "    def __call__(self, x: np.ndarray,y: np.ndarray) -> np.ndarray:\n",
    "        if prob(self.p):\n",
    "            if self.verbose:\n",
    "                print(f\"Augmenting: Applying {self.name}\")\n",
    "            return self.augment(x,y)\n",
    "        else:\n",
    "            return x,y\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "class Flip(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, axis: int = 0):\n",
    "        super().__init__(p)\n",
    "        self.axis = axis # 1 for horizontal, 0 for vertical\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        return np.flip(x, axis=self.axis),np.flip(y, axis=self.axis)\n",
    "\n",
    "class Rotate(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, angle: float = np.pi/4):\n",
    "        super().__init__(p)\n",
    "        self.angle = angle\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        # Rotate image and fill with zeros\n",
    "        # Random angle between -angle and angle\n",
    "        angle = np.random.uniform(-self.angle, self.angle)\n",
    "        # return rotate(x, angle, resize=False, mode=\"constant\", cval=0),rotate(y, angle, resize=False, mode=\"constant\", cval=0)\n",
    "        # Batched rotate\n",
    "        return np.array([rotate(img, angle, resize=False, mode=\"constant\", cval=0) for img in x]),np.array([rotate(img, angle, resize=False, mode=\"constant\", cval=0) for img in y])\n",
    "class Noise(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, mean: float = 0.0, std: float = 0.1):\n",
    "        super().__init__(p)\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        noise = np.random.normal(self.mean, self.std, x.shape)\n",
    "        return (x + noise, y)\n",
    "\n",
    "class Mask(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, max_n_masks: int = 10, mask_size: float = 0.5):\n",
    "        super().__init__(p)\n",
    "        self.max_n_masks = max_n_masks\n",
    "        self.mask_size = mask_size\n",
    "    def augment(self, x: np.ndarray, y:np.ndarray) -> np.ndarray:\n",
    "        # Random number of masks\n",
    "        n_masks = np.random.randint(1, self.max_n_masks)\n",
    "        w = x.shape[-3]\n",
    "        h = x.shape[-2]\n",
    "        for _ in range(n_masks):\n",
    "            # Random mask size\n",
    "            mask_size = np.random.uniform(low=self.mask_size/2, high=self.mask_size)\n",
    "            # Random mask position\n",
    "            x1 = np.random.randint(0, w)\n",
    "            y1 = np.random.randint(0, h)\n",
    "            x2 = int(x1 + w * mask_size)\n",
    "            y2 = int(y1 + h * mask_size)\n",
    "            x[:,..., x1:x2, y1:y2,:] = 0\n",
    "        return (x, y)\n",
    "\n",
    "class Translate(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, factor: float = 0.5):\n",
    "        super().__init__(p)\n",
    "        self.factor = factor\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        # Random translation factor\n",
    "        tx = np.random.uniform(-self.factor, self.factor) * x.shape[0]\n",
    "        ty = np.random.uniform(-self.factor, self.factor) * x.shape[1]\n",
    "        # Affine transform, grayscale image so no need to transform channels\n",
    "        tform = AffineTransform(translation=(tx, ty))\n",
    "        # Apply transform, Image will be filled with zeros\n",
    "        # x = warp(x, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # y = warp(y, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # Batched warp\n",
    "        x = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in x])\n",
    "        y = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in y])\n",
    "        return x,y\n",
    "\n",
    "class Shear(Augmentation):\n",
    "    def __init__(self, p: float = 0.5, factor: float = 0.5):\n",
    "        super().__init__(p)\n",
    "        self.factor = factor\n",
    "    def augment(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        # Random shear factor\n",
    "        shear_factor = np.random.uniform(-self.factor, self.factor)\n",
    "        # Create affine transform\n",
    "        tform = AffineTransform(shear=shear_factor)\n",
    "        # Use warp to apply transform\n",
    "        # x = warp(x, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # y = warp(y, tform.inverse, mode=\"constant\", cval=0)\n",
    "        # Batched warp\n",
    "        x = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in x])\n",
    "        y = np.array([warp(img, tform.inverse, mode=\"constant\", cval=0) for img in y])\n",
    "        return x,y\n",
    "class Augmentor:\n",
    "    \"\"\"\n",
    "    Augmentations:\n",
    "    flip_x: float\n",
    "        Probability of flipping the image horizontally\n",
    "    flip_y: float\n",
    "        Probability of flipping the image vertically\n",
    "    rotate: float\n",
    "        Probability of rotating the image\n",
    "    radians: float\n",
    "        Maximum rotation angle in radians\n",
    "    translate: float\n",
    "        Probability of translating the image\n",
    "    noise: float\n",
    "        Probability of adding noise to the image\n",
    "    noise_std: float\n",
    "        Standard deviation of the noise\n",
    "    noise_mean: float\n",
    "        Mean of the noise\n",
    "    mask: float\n",
    "        Probability of masking the image\n",
    "    max_n_masks: int\n",
    "        Maximum number of masks\n",
    "    mask_size: float\n",
    "        Maximum size of the mask as a fraction of the image size\n",
    "    shear: float\n",
    "        Probability of shearing the image\n",
    "    shear_factor: float\n",
    "        Maximum shear factor\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                flip_x:float=0.25,\n",
    "                flip_y:float=0.25,\n",
    "                rotate:float=0.5,\n",
    "                radians:float=np.pi/6,\n",
    "                translate:float=0.2,\n",
    "                noise:float=0.25,\n",
    "                noise_std:float=0.1,\n",
    "                noise_mean:float=0.1,\n",
    "                mask:float=0.8,\n",
    "                max_n_masks:int=10,\n",
    "                mask_size:float=0.25,\n",
    "                shear:float=0.1,\n",
    "                shear_factor:float=0.4,\n",
    "                verbose:bool=False\n",
    "                ):\n",
    "        self.verbose = verbose\n",
    "        self._active = True\n",
    "        Augmentation.verbose = self.verbose\n",
    "        self.augmentations = {}\n",
    "        if noise > 0:\n",
    "            self.augmentations[\"noise\"] = Noise(p=noise, std=noise_std, mean=noise_mean)\n",
    "        if flip_x > 0:\n",
    "            self.augmentations[\"flip_x\"] = Flip(p=flip_x, axis=1)\n",
    "            # self.augmentations.append(Flip(p=flip_x, axis=1))\n",
    "        if flip_y > 0:\n",
    "            self.augmentations[\"flip_y\"] = Flip(p=flip_y, axis=0)\n",
    "            # self.augmentations.append(Flip(p=flip_y, axis=0))\n",
    "        if rotate > 0:\n",
    "            self.augmentations[\"rotate\"] = Rotate(p=rotate, angle=radians)\n",
    "            # self.augmentations.append(Rotate(p=rotate, angle=radians))\n",
    "        if translate > 0:\n",
    "            self.augmentations[\"translate\"] = Translate(p=translate, factor=translate)\n",
    "            # self.augmentations.append(Translate(p=translate, factor=translate))\n",
    "        if mask > 0:\n",
    "            self.augmentations[\"mask\"] = Mask(p=mask, max_n_masks=max_n_masks, mask_size=mask_size)\n",
    "            # self.augmentations.append(Mask(p=mask, max_n_masks=max_n_masks, mask_size=mask_size))\n",
    "        if shear > 0:\n",
    "            self.augmentations.append(Shear(p=shear, factor=shear_factor))\n",
    "    def __call__(self, x: np.ndarray,y:np.ndarray) -> np.ndarray:\n",
    "        if self._active:\n",
    "            if x.shape != y.shape:\n",
    "                raise Exception(\"x and y must have the same shape\")\n",
    "            if len(x.shape) < 4:\n",
    "                x = x[np.newaxis,...]\n",
    "                y = y[np.newaxis,...]\n",
    "            for aug in self.augmentations.values():\n",
    "                x,y = aug(x,y)\n",
    "        return x, y\n",
    "    @property\n",
    "    def keys(self):\n",
    "        return list(self.augmentations.keys())\n",
    "    @property\n",
    "    def active(self):\n",
    "        return self._active\n",
    "    def scale_probability(self, key:str, factor:float):\n",
    "        if self.verbose:\n",
    "            print(f\"Scaling probability of {key} by {factor:3.3e}: {self.augmentations[key].p:3.3e} -> {self.augmentations[key].p * factor:3.3e}\")\n",
    "        self.augmentations[key].p *= factor\n",
    "    def set_active(self, active:bool):\n",
    "        self._active = active\n",
    "    def __repr__(self):\n",
    "        return f\"Augmentor({', '.join([f'{k}: {v.p:3.3e}' for k,v in self.augmentations.items()])})\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d2e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "def load_model(path,custom_objects=None,compile=True):\n",
    "    m = keras.models.load_model(path,custom_objects=custom_objects,compile=compile)\n",
    "    print(m.summary())\n",
    "    return m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "54cf780b",
   "metadata": {},
   "source": [
    "## Dice and Focal Loss - Custom FocalDiceLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b221a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dice loss for keras\n",
    "def dice_coef(y_true,y_pred, smooth=100):        \n",
    "    \n",
    "    intersection = K.sum(y_true * y_pred)\n",
    "    dice = (2. * intersection + smooth) / (K.sum(y_true) + K.sum(y_pred) + smooth)\n",
    "    return dice\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -K.log(dice_coef(y_true, y_pred))\n",
    "\n",
    "# Custom loss function for keras containing dice loss and binary focal loss\n",
    "class FocalDiceLoss(keras.losses.Loss):\n",
    "    def __init__(self, w_focal,w_dice,gamma=2.0, alpha=0.25, smooth=100, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.smooth = smooth\n",
    "        self.focal_loss = BinaryFocalCrossentropy(gamma=gamma, alpha=alpha)\n",
    "        self.w_focal = w_focal\n",
    "        self.w_dice = w_dice\n",
    "    def call(self, y_true, y_pred):\n",
    "        # Compute focal loss\n",
    "        y_true = K.flatten(y_true)\n",
    "        y_pred = K.flatten(y_pred)\n",
    "        dice_loss = dice_coef_loss(y_true, y_pred)\n",
    "        focal_loss = self.focal_loss(y_true, y_pred)\n",
    "        return self.w_dice*dice_loss + self.w_focal*focal_loss\n",
    "    \n",
    "# Test loss function\n",
    "def test_loss():\n",
    "    y_true = np.random.randint(0,2,(100,100)).astype(np.float32)\n",
    "    y_pred = np.random.rand(100,100).astype(np.float32)\n",
    "    loss = FocalDiceLoss(0.5,0.5)(y_true,y_pred)\n",
    "    print(loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "799abdd0",
   "metadata": {},
   "source": [
    "## Pre processing class\n",
    "Used to reshape the list of images to the correct format for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db532fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreProcessor:\n",
    "    def __init__(self, W:int,H:int,C:int,batch_size:int, per_batch:int, augmentor:Augmentor):\n",
    "        self.W = W\n",
    "        self.H = H\n",
    "        self.C = C\n",
    "        self.per_batch = per_batch\n",
    "        self.augmentor = augmentor\n",
    "        self.index = np.tile(np.arange(batch_size),(1,per_batch)).reshape(-1)\n",
    "    def __call__(self, x:List[np.ndarray],augment:bool=True):\n",
    "        y = x[-1]\n",
    "        x = x[:-1]\n",
    "        x = np.array(x)\n",
    "        # Shape: (batch_size, per_batch, height, width, channels)\n",
    "        # Reshape to: (batch_size*per_batch, height, width, channels)\n",
    "        x = x.reshape((-1,self.W,self.H,self.C))\n",
    "        # Repeat y per_batch times to match the shape of x.\n",
    "        # y = np.repeat(y[:,np.newaxis],per_batch, axis=1)\n",
    "        # Reshape to: (batch_size*per_batch, height, width, channels) with repeatition of y\n",
    "        y = y[self.index]\n",
    "        # Augment the data.\n",
    "        if augment:\n",
    "            x, y = self.augmentor(x,y)\n",
    "        return x, y\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5969164d",
   "metadata": {},
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c7fb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Original code.\n",
    "# learning_rate = 0.01\n",
    "# optim = optimizers.Adam(lr=learning_rate)\n",
    "# model.compile(loss=\"mse\",\n",
    "#               optimizer=optim)\n",
    "##\n",
    "W,H,C = 256,256,1\n",
    "\n",
    "custom_lr = 0.0001 #0.00005, Original. NOTE: I used 0.0005 for the first 50 Epochs.\n",
    "weight_decay = 0.0 # Weight decay for regularization.\n",
    "clipvalue = 2 # Clipvalue for regularization.\n",
    "augmentation_warmup = 0 # Warmup augmentations. How many epochs to train without augmentations.\n",
    "fp16 = False # Mixed precision training, i.e. use float16 instead of float32: Faster training, but less accurate.\n",
    "# NOTE: Might need to replace the keyword \"learning_rate\" with \"lr\" since i used an newer version of Keras, see code below.\n",
    "optim = Adam(learning_rate=custom_lr,decay=weight_decay,clipvalue=clipvalue)\n",
    "# custom_optimizer = Adam(lr=custom_lr,decay=weight_decay) # Replaced RMSprop for Adam.\n",
    "custom_loss = FocalDiceLoss(0.5,0.5) # Custom loss function.\n",
    "custom_metric = dice_coef # Custom metric function.\n",
    "augmentor = Augmentor(translate=0, # No translation. Due to lack of speed.\n",
    "                      shear=0, # No shear. Due to lack of speed.\n",
    "                      rotate=0, # No rotation. Due to lack of speed.\n",
    "                      mask=0.8, # Probability of masking the image.\n",
    "                      mask_size=0.2, # Maximum size of the mask as a fraction of the image size.\n",
    "                      max_n_masks=8, # Maximum number of masks to apply.\n",
    "                      noise=0.4, # Probability of adding Gaussian noise to the image.\n",
    "                      noise_mean=0.05, # Mean of the noise.\n",
    "                      noise_std=0.1, # Standard deviation of the noise.\n",
    "                      ) # Augmentation of the data.\n",
    "pre_processor = PreProcessor(W,H,C,batch_size,per_batch,augmentor)\n",
    "\n",
    "if augmentation_warmup > 0:\n",
    "    augmentor.set_active(False)\n",
    "\n",
    "model.compile(loss=custom_loss,\n",
    "              optimizer=optim,\n",
    "              metrics=[custom_metric])\n",
    "name = \"unet_segmentation\"\n",
    "# Create model directory.\n",
    "if not os.path.exists(\"./models\"):\n",
    "    os.makedirs(\"./models\")\n",
    "model_dir = os.path.join(\"./models\", name)\n",
    "n_epochs = 50\n",
    "\n",
    "best = np.inf\n",
    "batches = len(gen_train)\n",
    "total_batches = batches * n_epochs # Every batch is a training step.\n",
    "# Define the history arrays for speed.\n",
    "train_epoch_history = np.zeros(n_epochs)\n",
    "valid_epoch_history = np.zeros(n_epochs)\n",
    "train_batch_history = np.zeros(total_batches)\n",
    "counter = 0\n",
    "h = 0 # Initial loss for progress bar.\n",
    "\n",
    "# NOTE: Are you satisfied with the optimizer and its parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe296d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_threshold(y_pred:np.ndarray,threshold:float=0.5):\n",
    "    y_pred = np.where(y_pred > threshold, 1, 0)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f98273a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(generator: DataGenerator,\n",
    "                pre_processor:PreProcessor,\n",
    "                array_labels:List[str],\n",
    "                model:Model=None,\n",
    "                batch_idx:int=None,\n",
    "                augment:bool=False,\n",
    "                threshold:float=0.5,\n",
    "                save:bool=False,\n",
    "                save_path:str=\"./figures/\",\n",
    "                figure_name:str=\"sample.png\",\n",
    "                title:str=\"Samples\",):\n",
    "    # Get a batch of data.\n",
    "    idx = batch_idx if batch_idx is not None else np.random.randint(0,len(generator))\n",
    "    print(f\"Plotting sample {idx}\")\n",
    "    data = generator[idx]\n",
    "    # Preprocess the data.\n",
    "    x, y = pre_processor(data,augment=augment)\n",
    "    # Grid with one of each array_label.\n",
    "    n_formats = len(array_labels)-1\n",
    "\n",
    "    \n",
    "    rows = 2 if not model else 3\n",
    "    cols = n_formats\n",
    "    preds = model.predict(x) if model else None\n",
    "    if threshold:\n",
    "        preds = prediction_threshold(preds,threshold) if model else None\n",
    "    # Create a figure with the correct number of subplots.\n",
    "    fig = plt.figure(figsize=(16, 10))\n",
    "    grid = ImageGrid(fig, 111,\n",
    "                    nrows_ncols=(rows, cols), \n",
    "                    axes_pad=[0.0, 0.35],\n",
    "                    )\n",
    "    for i, ax in enumerate(grid):\n",
    "        # Get the row and column index.\n",
    "        # Create masked images.\n",
    "        inp = np.ma.masked_array(x[i], mask=y[i])\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        # Plot the data.\n",
    "        if row == 0:\n",
    "            # ax.imshow(x[i+col*n_formats], cmap='gray')\n",
    "            ax.imshow(inp, cmap='gray')\n",
    "            ax.set_title(f\"{array_labels[col]}\", fontsize=20)\n",
    "        elif row == 1:\n",
    "            ax.imshow(y[i], cmap='Reds')\n",
    "            ax.imshow(x[i], cmap='gray', alpha=0.5)\n",
    "            # Underlay the input image.\n",
    "            ax.set_title(f\"{array_labels[-1]}\", fontsize=20)\n",
    "        else:\n",
    "            # ax.imshow(preds[i], cmap='Blues')\n",
    "            ax.imshow(preds, cmap='Blues')\n",
    "            # Underlay the input image.\n",
    "            ax.imshow(x[i], cmap='gray', alpha=0.5)\n",
    "            ax.set_title(f\"Prediction\", fontsize=20)\n",
    "\n",
    "        ax.axis('off')\n",
    "    fig.suptitle(title, fontsize=30)\n",
    "    # Tight \n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        fig.savefig(os.path.join(save_path,figure_name))\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "%matplotlib inline\n",
    "for i in range(1):\n",
    "    plot_sample(gen_val, pre_processor, array_labels, model=best_model,threshold=0.5)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f52fb868",
   "metadata": {},
   "source": [
    "## Training Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e34488f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if fp16:\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "    print('Compute dtype: %s' % policy.compute_dtype)\n",
    "    print('Variable dtype: %s' % policy.variable_dtype)\n",
    "augmentation_start = batches*augmentation_warmup\n",
    "print(\"Start training... This may take a while.\")\n",
    "for epoch in range(n_epochs):\n",
    "    validating_loss = []\n",
    "    pbar = tqdm(enumerate(gen_train)) # Progess bar to make it less boring, and trackable.\n",
    "    for idx, xy in pbar:\n",
    "        x,y = pre_processor(xy)\n",
    "        h = model.train_on_batch(x, y)[0]\n",
    "        train_batch_history[counter] = h\n",
    "        counter += 1\n",
    "        if counter > augmentation_start and not augmentor.active:\n",
    "            augmentor.set_active(True)\n",
    "        if (idx+1)%10==0 or idx==0:\n",
    "            pbar.set_description(f\"Training Epoch {epoch+1}/{n_epochs}. {idx+1}/{batches} Batch. Training Loss MSE: {h:.3e}\")\n",
    "    # for idx, (t1, t2) in enumerate(gen_val):\n",
    "    #     validating_loss.append(model.test_on_batch(t1, t2)[0])\n",
    "    for idx, xy in enumerate(gen_val):\n",
    "        x,y = pre_processor(xy)\n",
    "        h = model.test_on_batch(x, y)[0]\n",
    "        validating_loss.append(h)\n",
    "    train_epoch_history[epoch] = np.mean(train_batch_history[epoch*batches:(epoch+1)*batches])\n",
    "    valid_epoch_history[epoch] = np.mean(validating_loss)\n",
    "    if valid_epoch_history[epoch] < best:\n",
    "        best = valid_epoch_history[epoch]\n",
    "        model.save(model_dir)\n",
    "        plot_sample(gen_train,\n",
    "                    pre_processor,\n",
    "                    array_labels,\n",
    "                    model,\n",
    "                    save=True,\n",
    "                    save_path=os.path.join(model_dir,\"figures\"),\n",
    "                    figure_name=f\"train_{epoch+1}.png\",\n",
    "                    title=f\"Epoch {epoch+1} Training Sample\",\n",
    "                    batch_idx=0\n",
    "                )\n",
    "        plot_sample(gen_val,\n",
    "                    pre_processor,\n",
    "                    array_labels,\n",
    "                    model,\n",
    "                    save=True,\n",
    "                    save_path=os.path.join(model_dir,\"figures\"),\n",
    "                    figure_name=f\"validation_{epoch+1}.png\",\n",
    "                    title=f\"Epoch {epoch+1} Validation Sample\",\n",
    "                )\n",
    "    print(f\"Epoch: {epoch + 1:2d}. Average loss - Training: {train_epoch_history[epoch]:.3e}, Validation: {valid_epoch_history[epoch]:.3e}\")\n",
    "# NOTE: Plotting the losses helps a lot.\n",
    "# NOTE: What does plotting the training data tell you? Should you plot something else?\n",
    "# NOTE: What should one do with the validation data? The data generator has a 'validation_data' argument as well.\n",
    "# NOTE: When should one stop? Did you overtrain? Did you train for long enough?\n",
    "# NOTE: Think abouct implementing Early Stopping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49814684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the losses.\n",
    "# Plot in separate window.\n",
    "epoch_to_batch = np.arange(0, total_batches, batches)\n",
    "%matplotlib qt\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epoch_to_batch, train_epoch_history, label=\"Training Loss\",color=\"C0\")\n",
    "plt.plot(train_batch_history, label=\"Training Loss per Batch\",alpha=0.5, color=\"C0\")\n",
    "# Center the plot around the epoch_to_batch.\n",
    "# plt.xlim(epoch_to_batch[0], epoch_to_batch[-1])\n",
    "plt.ylim(np.min(train_batch_history), np.max(train_epoch_history))\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss - MSE\")\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epoch_to_batch, valid_epoch_history, label=\"Validation Loss\",color=\"C1\")\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss - MSE\")\n",
    "# Increase spacing between subplots.\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()\n",
    "# Bottom two plots as one plot.\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epoch_to_batch, train_epoch_history, label=\"Training Loss\",color=\"C0\")\n",
    "plt.plot(epoch_to_batch, valid_epoch_history, label=\"Validation Loss\",color=\"C1\")\n",
    "plt.grid()\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel(\"Batches\")\n",
    "plt.ylabel(\"Loss - MSE\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea7225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.losses\n",
    "keras.losses.custom_loss = FocalDiceLoss\n",
    "best_model = load_model(model_dir,compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a29b7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(gen_test, pre_processor, array_labels, model=best_model,threshold=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce3fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model: Model, gen_data: DataGenerator,n: int = batch_size, pre_processer: PreProcessor = None):\n",
    "    xy = gen_data[np.random.randint(0, len(gen_data))]\n",
    "    x,y = pre_processer(x,y)\n",
    "    prediction = model.predict(x)\n",
    "    cols = 3\n",
    "    plt.figure(figsize=(16, 10* n))\n",
    "    for idx in range(n):\n",
    "        plt.subplot(n, 3, idx * cols + 1)\n",
    "        plt.imshow(t1[idx, :, :], cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.title('INPUT')\n",
    "        # No axis labels.\n",
    "        plt.xticks([])\n",
    "        plt.subplot(n, 3, idx * cols + 2)\n",
    "        plt.imshow(t2[idx, :, :], cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.title('GT')\n",
    "        plt.xticks([])\n",
    "\n",
    "        plt.subplot(n, 3, idx * cols + 3)\n",
    "        plt.imshow(prediction[idx, :, :], cmap='gray')\n",
    "        plt.colorbar()\n",
    "        plt.title('PRED')\n",
    "        plt.xticks([])\n",
    "        # Plot difference\n",
    "        # Print difference\n",
    "        print(f\"MSE: {np.mean((t2[idx, :, :] - prediction[idx, :, :])**2):.3e}\")\n",
    "    plt.show()\n",
    "        \n",
    "    print(f\"Average:{np.mean((t2 - prediction)**2):.3e}\")\n",
    "    # NOTE: What do the predictions mean? What values do they take on?\n",
    "%matplotlib qt\n",
    "test_model(best_model, gen_train,2)#,augmentor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b12c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the encoder part of the model.\n",
    "# encoder = Model(model.input, model.get_layer('input_2').output)\n",
    "encoder = Model(model.get_layer('Encoder').input,model.get_layer('Encoder').output)\n",
    "decoder = Model(model.get_layer('Decoder').input,model.get_layer('Decoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a158a1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_encodings_grid(encodings: List[np.ndarray]):\n",
    "    n_encodings = len(encodings)\n",
    "    print(f\"Number of encodings: {n_encodings}\")\n",
    "    # Create a grid of images.\n",
    "    for encoding_layer in encodings:\n",
    "        # n_encodings different encodings.\n",
    "        # Each encoding has n_channels different channels. The figure will have sqrt(n_channels) rows and columns.\n",
    "        n_channels = encoding_layer.shape[-1]\n",
    "        rows = int(np.ceil((np.sqrt(n_channels))))\n",
    "        cols = int(np.ceil((np.sqrt(n_channels))))\n",
    "        print(f\"Number of channels: {n_channels}. Rows: {rows}. Cols: {cols}.\")\n",
    "        # Create a figure with the correct number of subplots.\n",
    "        fig = plt.figure(figsize=(16, 10))\n",
    "        grid = ImageGrid(fig, 111,\n",
    "                         nrows_ncols=(rows, cols), \n",
    "                         axes_pad=0.0,\n",
    "                         )\n",
    "        # Plot each channel.\n",
    "        for idx, ax in zip(range(n_channels),grid):\n",
    "            # Plot the channel.\n",
    "            ax.imshow(encoding_layer[:, :, idx], cmap='gray')\n",
    "            # No axis labels.\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            # Set the title.\n",
    "        plt.subplots_adjust(wspace=0, hspace=0)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da353294",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val = gen_val[0]\n",
    "encodings_batched = encoder.predict(x_val)\n",
    "decoded = decoder.predict(encodings_batched[::-1])\n",
    "encodings = [enc[0] for enc in encodings_batched]\n",
    "plot_encodings_grid([encodings[-1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
